{
  "url": "http://docs.mongodb.com/",
  "includeInGlobalSearch": false,
  "documents": [{
      "slug": "/about.html",
      "title": "About MongoDB Documentation \u2014 MongoDB Manual 3.4",
      "text": "About MongoDB Documentation\u00b6 On this page License Editions Version and Revisions Report an Issue or Make a Change Request Contribute to the Documentation The MongoDB Manual contains comprehensive documentation on MongoDB. This page describes the manual\u2019s licensing, editions, and versions, and describes how to make a change request and how to contribute to the manual. License\u00b6 This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License \u00a9 MongoDB, Inc. 2008-2017 Editions\u00b6 In addition to the MongoDB Manual, you can also access this content in the following editions: HTML tar.gz EPUB Format MongoDB Reference documentation is also available as part of dash. You can also access the MongoDB Man Pages which are also distributed with the official MongoDB Packages. Version and Revisions\u00b6 This version of the manual reflects version 3.4 of MongoDB. See the MongoDB Documentation Project Page for an overview of all editions and output formats of the MongoDB Manual. You can see the full revision history and track ongoing improvements and additions for all versions of the manual from its GitHub repository. This edition reflects \u201cDOCS-9808\u201d branch of the documentation as of the \u201c7bc28aa36c4468bb077c428aa9a1772a78ba0794\u201d revision. This branch is explicitly accessible via \u201chttps://docs.mongodb.com/DOCS-9808\u201d and you can always reference the commit of the current manual in the release.txt file. The most up-to-date, current, and stable version of the manual is always available at \u201chttp://docs.mongodb.org/manual/\u201d. Report an Issue or Make a Change Request\u00b6 To report an issue with this manual or to make a change request, file a ticket at the MongoDB DOCS Project on Jira. Contribute to the Documentation\u00b6 The entire documentation source for this manual is available in the mongodb/docs repository, which is one of the MongoDB project repositories on GitHub. To contribute to the documentation, you can open a GitHub account, fork the mongodb/docs repository, make a change, and issue a pull request. In order for the documentation team to accept your change, you must complete the MongoDB Contributor Agreement. You can clone the repository by issuing the following command at your system shell: git clone git://github.com/mongodb/docs.git About the Documentation Process\u00b6 The MongoDB Manual uses Sphinx, a sophisticated documentation engine built upon Python Docutils. The original reStructured Text files, as well as all necessary Sphinx extensions and build tools, are available in the same repository as the documentation. For more information on the MongoDB documentation process, see: Style Guide and Documentation Conventions MongoDB Documentation Practices and Processes MongoDB Manual Organization MongoDB Documentation Build System If you have any questions, please feel free to open a Jira Case. \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration.html",
      "title": "Administration \u2014 MongoDB Manual 3.4",
      "text": "Administration\u00b6 The administration documentation addresses the ongoing operation and maintenance of MongoDB instances and deployments. This documentation includes both high level overviews of these concerns as well as tutorials that cover specific procedures and processes for operating MongoDB. See also The MongoDB Manual contains administrative documentation and tutorials thoughout several sections. See Replica Set Tutorials and Sharding for additional tutorials and information. Production Notes Operations Checklist Development Checklist Performance Database Profiler Database Profiler Output Disable Transparent Huge Pages (THP) UNIX ulimit Settings Configuration and Maintenance Run-time Database Configuration Upgrade to the Latest Revision of MongoDB Manage mongod Processes Terminate Running Operations Rotate Log Files Data Center Awareness Operational Segregation in MongoDB Deployments Zones Manage Shard Zones Segmenting Data by Location Tiered Hardware for Varying SLA or SLO Segmenting Data by Application or Customer Distributed Local Writes for Insert Only Workloads Manage Shard Zones MongoDB Backup Methods Back Up and Restore with Filesystem Snapshots Back Up and Restore with MongoDB Tools Restore a Replica Set from MongoDB Backups Backup and Restore Sharded Clusters Back Up a Sharded Cluster with File System Snapshots Back Up a Sharded Cluster with Database Dumps Schedule Backup Window for Sharded Clusters Restore a Sharded Cluster Recover a Standalone after an Unexpected Shutdown Monitoring for MongoDB Monitor MongoDB With SNMP on Linux Monitor MongoDB Windows with SNMP Troubleshoot SNMP \u2190 Database References Production Notes \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/contents.html",
      "title": "MongoDB Manual Contents \u2014 MongoDB Manual 3.4",
      "text": "MongoDB Manual Contents\u00b6 See About MongoDB Documentation for more information about the MongoDB Documentation project, this Manual and additional editions of this text. Introduction Getting Started Databases and Collections Views Capped Collections Documents BSON Types Comparison/Sort Order MongoDB Extended JSON Installation Install MongoDB Community Edition Install on Linux Install on Red Hat Install on SUSE Install on Amazon Install on Ubuntu Install on Debian Install From Tarball Install on OS X Install on Windows Install MongoDB Enterprise Install on Linux Install on Red Hat Install on Ubuntu Install on Debian Install on SUSE Install on Amazon Install From Tarball Install on OS X Install on Windows Verify Integrity of MongoDB Packages The mongo Shell Configure the mongo Shell Access the mongo Shell Help Write Scripts for the mongo Shell Data Types in the mongo Shell mongo Shell Quick Reference MongoDB CRUD Operations Insert Documents Insert Methods Query Documents Query on Embedded/Nested Documents Query an Array Query an Array of Embedded Documents Project Fields to Return from Query Query for Null or Missing Fields Iterate a Cursor in the mongo Shell Update Documents Update Methods Delete Documents Delete Methods Bulk Write Operations SQL to MongoDB Mapping Chart Read Isolation (Read Concern) Write Acknowledgement (Write Concern) MongoDB CRUD Concepts Atomicity and Transactions Read Isolation, Consistency, and Recency Distributed Queries Distributed Write Operations Perform Two Phase Commits Linearizable Reads via findAndModify Query Plans Query Optimization Evaluate Performance of Current Operations Optimize Query Performance Write Operation Performance Explain Results Analyze Query Performance Tailable Cursors Aggregation Aggregation Pipeline Aggregation Pipeline Optimization Aggregation Pipeline Limits Aggregation Pipeline and Sharded Collections Example with ZIP Code Data Example with User Preference Data Map-Reduce Map-Reduce and Sharded Collections Map Reduce Concurrency Map-Reduce Examples Perform Incremental Map-Reduce Troubleshoot the Map Function Troubleshoot the Reduce Function Aggregation Reference Aggregation Pipeline Quick Reference Aggregation Commands Aggregation Commands Comparison Variables in Aggregation Expressions SQL to Aggregation Mapping Chart Text Search Text Indexes Text Search Operators Text Search in the Aggregation Pipeline Text Search with Basis Technology Rosette Linguistics Platform Text Search Languages Data Models Data Modeling Introduction Document Validation Data Modeling Concepts Data Model Design Operational Factors and Data Models Data Model Examples and Patterns Model Relationships Between Documents Model One-to-One Relationships with Embedded Documents Model One-to-Many Relationships with Embedded Documents Model One-to-Many Relationships with Document References Model Tree Structures Model Tree Structures with Parent References Model Tree Structures with Child References Model Tree Structures with an Array of Ancestors Model Tree Structures with Materialized Paths Model Tree Structures with Nested Sets Model Specific Application Contexts Model Data for Atomic Operations Model Data to Support Keyword Search Model Monetary Data Model Time Data Data Model Reference Database References Administration Production Notes Operations Checklist Development Checklist Performance Database Profiler Database Profiler Output Disable Transparent Huge Pages (THP) UNIX ulimit Settings Configuration and Maintenance Run-time Database Configuration Upgrade to the Latest Revision of MongoDB Manage mongod Processes Terminate Running Operations Rotate Log Files Data Center Awareness Operational Segregation in MongoDB Deployments Zones Manage Shard Zones Segmenting Data by Location Tiered Hardware for Varying SLA or SLO Segmenting Data by Application or Customer Distributed Local Writes for Insert Only Workloads Manage Shard Zones MongoDB Backup Methods Back Up and Restore with Filesystem Snapshots Back Up and Restore with MongoDB Tools Restore a Replica Set from MongoDB Backups Backup and Restore Sharded Clusters Back Up a Sharded Cluster with File System Snapshots Back Up a Sharded Cluster with Database Dumps Schedule Backup Window for Sharded Clusters Restore a Sharded Cluster Recover a Standalone after an Unexpected Shutdown Monitoring for MongoDB Monitor MongoDB With SNMP on Linux Monitor MongoDB Windows with SNMP Troubleshoot SNMP Indexes Single Field Indexes Compound Indexes Multikey Indexes Multikey Index Bounds Text Indexes Specify a Language for Text Index Specify Name for text Index Control Search Results with Weights Limit the Number of Entries Scanned 2dsphere Indexes Find Restaurants with Geospatial Queries Query a 2dsphere Index GeoJSON Objects 2d Indexes Create a 2d Index Query a 2d Index 2d Index Internals Calculate Distance Using Spherical Geometry Hashed Indexes Index Properties TTL Indexes Expire Data from Collections by Setting TTL Unique Indexes Partial Indexes Case Insensitive Indexes Sparse Indexes Index Build Operations Build Indexes on Replica Sets Index Intersection Manage Indexes Measure Index Use Indexing Strategies Create Indexes to Support Your Queries Use Indexes to Sort Query Results Ensure Indexes Fit in RAM Create Queries that Ensure Selectivity Indexing Reference Storage Storage Engines WiredTiger Storage Engine Change Standalone to WiredTiger Change Replica Set to WiredTiger Change Sharded Cluster to WiredTiger Change Config Servers to WiredTiger MMAPv1 Storage Engine In-Memory Storage Engine Journaling Manage Journaling GridFS FAQ: MongoDB Storage Security Security Checklist Authentication Users Add Users Authentication Mechanisms SCRAM-SHA-1 MONGODB-CR x.509 Use x.509 Certificates to Authenticate Clients Enterprise Authentication Mechanisms Kerberos Authentication Configure MongoDB with Kerberos Authentication on Linux Configure MongoDB with Kerberos Authentication on Windows Troubleshoot Kerberos Authentication Configure MongoDB with Kerberos Authentication and Active Directory Authorization LDAP Proxy Authentication Authenticate Using SASL and LDAP with ActiveDirectory Authenticate Using SASL and LDAP with OpenLDAP Authenticate and Authorize Users Using Active Directory via Native LDAP LDAP Authorization Internal Authentication Enforce Keyfile Access Control in a Replica Set Enforce Keyfile Access Control in a Replica Set without Downtime Deploy Replica Set With Keyfile Access Control Enforce Keyfile Access Control in Sharded Cluster Deploy Sharded Cluster with Keyfile Access Control Use x.509 Certificate for Membership Authentication Upgrade from Keyfile Authentication to x.509 Authentication Enable Auth Manage Users and Roles Change Your Password and Custom Data Role-Based Access Control Built-In Roles User-Defined Roles Collection-Level Access Control Encryption Transport Encryption Configure mongod and mongos for TLS/SSL TLS/SSL Configuration for Clients Upgrade a Cluster to Use TLS/SSL Configure MongoDB for FIPS Encryption at Rest Configure Encryption Rotate Encryption Keys Auditing Configure Auditing Configure Audit Filters Security Hardening MongoDB Configuration Hardening Hardening Network Infrastructure Configure Linux iptables Firewall for MongoDB Configure Windows netsh Firewall for MongoDB Implement Field Level Redaction Security Reference Built-In Roles system.roles Collection system.users Collection Resource Document Privilege Actions System Event Audit Messages Create a Vulnerability Report Replication Replica Set Members Replica Set Primary Replica Set Secondary Members Priority 0 Replica Set Members Hidden Replica Set Members Delayed Replica Set Members Replica Set Arbiter Replica Set Oplog Replica Set Data Synchronization Replica Set Deployment Architectures Three Member Replica Sets Replica Sets Distributed Across Two or More Data Centers Replica Set High Availability Replica Set Elections Rollbacks During Replica Set Failover Replica Set Protocol Versions Master Slave Replication Replica Set Read and Write Semantics Write Concern for Replica Sets Read Preference Server Selection Algorithm Replica Set Tutorials Replica Set Deployment Tutorials Deploy a Replica Set Deploy a Replica Set for Testing and Development Deploy a Geographically Redundant Replica Set Add an Arbiter to Replica Set Convert a Standalone to a Replica Set Add Members to a Replica Set Remove Members from Replica Set Replace a Replica Set Member Member Configuration Tutorials Adjust Priority for Replica Set Member Prevent Secondary from Becoming Primary Configure a Hidden Replica Set Member Configure a Delayed Replica Set Member Configure Non-Voting Replica Set Member Convert a Secondary to an Arbiter Replica Set Maintenance Tutorials Change the Size of the Oplog Perform Maintenance on Replica Set Members Force a Member to Become Primary Resync a Member of a Replica Set Configure Replica Set Tag Sets Reconfigure a Replica Set with Unavailable Members Manage Chained Replication Change Hostnames in a Replica Set Configure a Secondary\u2019s Sync Target Troubleshoot Replica Sets Replication Reference Replica Set Configuration The local Database Replica Set Member States Read Preference Reference Sharding Sharded Cluster Components Shards Config Servers (metadata) Router (mongos) Shard Keys Hashed Sharding Deploy Sharded Cluster using Hashed Sharding Ranged Sharding Deploy Sharded Cluster using Ranged Sharding Zones Manage Shard Zones Segmenting Data by Location Tiered Hardware for Varying SLA or SLO Segmenting Data by Application or Customer Distributed Local Writes for Insert Only Workloads Administration Data Partitioning with Chunks Create Chunks in a Sharded Cluster Split Chunks in a Sharded Cluster Merge Chunks in a Sharded Cluster Modify Chunk Size in a Sharded Cluster Config Server Administration Replace a Config Server Upgrade Config Servers to Replica Set Upgrade Config Servers to Replica Set (Downtime) Balancer Administration Manage Sharded Cluster Balancer Migrate Chunks in a Sharded Cluster View Cluster Configuration Migrate a Sharded Cluster to Different Hardware Add Shards to a Cluster Remove Shards from an Existing Sharded Cluster Clear jumbo Flag Back Up Cluster Metadata Convert Sharded Cluster to Replica Set Convert a Replica Set to a Sharded Cluster Sharding Reference Operational Restrictions Troubleshoot Sharded Clusters Config Database Frequently Asked Questions FAQ: MongoDB Fundamentals FAQ: Indexes FAQ: Concurrency FAQ: Sharding with MongoDB FAQ: Replication and Replica Sets FAQ: MongoDB Storage FAQ: MongoDB Diagnostics Reference Operators Query and Projection Operators Comparison Query Operators $eq $gt $gte $lt $lte $ne $in $nin Logical Query Operators $or $and $not $nor Element Query Operators $exists $type Evaluation Query Operators $mod $regex $text $where Geospatial Query Operators $geoWithin $geoIntersects $near $nearSphere $geometry $minDistance $maxDistance $center $centerSphere $box $polygon $uniqueDocs Array Query Operators $all $elemMatch (query) $size Bitwise Query Operators $bitsAllSet $bitsAnySet $bitsAllClear $bitsAnyClear $comment Projection Operators $ (projection) $elemMatch (projection) $meta $slice (projection) Update Operators Field Update Operators $inc $mul $rename $setOnInsert $set $unset $min $max $currentDate Array Update Operators $ (update) $addToSet $pop $pullAll $pull $pushAll $push $each $slice $sort $position Bitwise Update Operator $bit Isolation Update Operator $isolated Aggregation Pipeline Operators Pipeline Aggregation Stages $collStats (aggregation) $project (aggregation) $match (aggregation) $redact (aggregation) $limit (aggregation) $skip (aggregation) $unwind (aggregation) $group (aggregation) $sample (aggregation) $sort (aggregation) $geoNear (aggregation) $lookup (aggregation) $out (aggregation) $indexStats (aggregation) $facet (aggregation) $bucket (aggregation) $bucketAuto (aggregation) $sortByCount (aggregation) $addFields (aggregation) $replaceRoot (aggregation) $count (aggregation) $graphLookup (aggregation) Boolean Aggregation Operators $and (aggregation) $or (aggregation) $not (aggregation) Set Operators (Aggregation) $setEquals (aggregation) $setIntersection (aggregation) $setUnion (aggregation) $setDifference (aggregation) $setIsSubset (aggregation) $anyElementTrue (aggregation) $allElementsTrue (aggregation) Comparison Aggregation Operators $cmp (aggregation) $eq (aggregation) $gt (aggregation) $gte (aggregation) $lt (aggregation) $lte (aggregation) $ne (aggregation) Arithmetic Aggregation Operators $abs (aggregation) $add (aggregation) $ceil (aggregation) $divide (aggregation) $exp (aggregation) $floor (aggregation) $ln (aggregation) $log (aggregation) $log10 (aggregation) $mod (aggregation) $multiply (aggregation) $pow (aggregation) $sqrt (aggregation) $subtract (aggregation) $trunc (aggregation) String Aggregation Operators $concat (aggregation) $indexOfBytes (aggregation) $indexOfCP (aggregation) $split (aggregation) $strLenBytes (aggregation) $strLenCP (aggregation) $strcasecmp (aggregation) $substr (aggregation) $substrBytes (aggregation) $substrCP (aggregation) $toLower (aggregation) $toUpper (aggregation) Text Search Aggregation Operators $meta (aggregation) Array Aggregation Operators $arrayElemAt (aggregation) $concatArrays (aggregation) $filter (aggregation) $indexOfArray (aggregation) $isArray (aggregation) $range (aggregation) $reverseArray (aggregation) $reduce (aggregation) $size (aggregation) $slice (aggregation) $zip (aggregation) $in (aggregation) Aggregation Variable Operators $map (aggregation) $let (aggregation) Aggregation Literal Operators $literal (aggregation) Date Aggregation Operators $dayOfYear (aggregation) $dayOfMonth (aggregation) $dayOfWeek (aggregation) $year (aggregation) $month (aggregation) $week (aggregation) $hour (aggregation) $minute (aggregation) $second (aggregation) $millisecond (aggregation) $dateToString (aggregation) $isoDayOfWeek (aggregation) $isoWeek (aggregation) $isoWeekYear (aggregation) Conditional Aggregation Operators $cond (aggregation) $ifNull (aggregation) $switch (aggregation) Data Type Aggregation Operators $type (aggregation) Group Accumulator Operators $sum (aggregation) $avg (aggregation) $first (aggregation) $last (aggregation) $max (aggregation) $min (aggregation) $push (aggregation) $addToSet (aggregation) $stdDevPop (aggregation) $stdDevSamp (aggregation) Query Modifiers $comment $explain $hint $maxScan $maxTimeMS $max $min $orderby $returnKey $showDiskLoc $snapshot $query $natural Database Commands Aggregation Commands aggregate count distinct group mapReduce Geospatial Commands geoNear geoSearch Query and Write Operation Commands find insert update delete findAndModify getMore getLastError getPrevError resetError eval parallelCollectionScan Query Plan Cache Commands planCacheListFilters planCacheSetFilter planCacheClearFilters planCacheListQueryShapes planCacheListPlans planCacheClear Authentication Commands logout authenticate copydbgetnonce getnonce authSchemaUpgrade User Management Commands createUser updateUser dropUser dropAllUsersFromDatabase grantRolesToUser revokeRolesFromUser usersInfo Role Management Commands createRole updateRole dropRole dropAllRolesFromDatabase grantPrivilegesToRole revokePrivilegesFromRole grantRolesToRole revokeRolesFromRole rolesInfo invalidateUserCache Replication Commands replSetFreeze replSetGetStatus replSetInitiate replSetMaintenance replSetReconfig replSetStepDown replSetSyncFrom resync applyOps isMaster replSetGetConfig Sharding Commands flushRouterConfig addShard balancerStart balancerStatus balancerStop cleanupOrphaned checkShardingIndex enableSharding listShards removeShard getShardMap getShardVersion mergeChunks setShardVersion shardCollection shardingState unsetSharding split splitChunk splitVector medianKey moveChunk movePrimary isdbgrid addShardToZone removeShardFromZone updateZoneKeyRange Administration Commands renameCollection copydb dropDatabase listCollections drop create clone cloneCollection cloneCollectionAsCapped convertToCapped filemd5 createIndexes listIndexes dropIndexes fsync clean connPoolSync connectionStatus compact collMod reIndex setParameter getParameter repairDatabase repairCursor touch shutdown logRotate killOp currentOp setFeatureCompatibilityVersion Diagnostic Commands availableQueryOptions buildInfo collStats connPoolStats cursorInfo dataSize dbHash dbStats diagLogging driverOIDTest explain features getCmdLineOpts getLog hostInfo isSelf listCommands listDatabases netstat ping profile serverStatus shardConnPoolStats top validate whatsmyuri Internal Commands handshake recvChunkAbort recvChunkCommit recvChunkStart recvChunkStatus replSetFresh mapreduce.shardedfinish transferMods replSetHeartbeat replSetGetRBID migrateClone replSetElect writeBacksQueued writebacklisten System Events Auditing Commands logApplicationMessage mongo Shell Methods Collection Methods db.collection.aggregate() db.collection.bulkWrite() db.collection.count() db.collection.copyTo() db.collection.createIndex() db.collection.dataSize() db.collection.deleteOne() db.collection.deleteMany() db.collection.distinct() db.collection.drop() db.collection.dropIndex() db.collection.dropIndexes() db.collection.ensureIndex() db.collection.explain() db.collection.find() db.collection.findAndModify() db.collection.findOne() db.collection.findOneAndDelete() db.collection.findOneAndReplace() db.collection.findOneAndUpdate() db.collection.getIndexes() db.collection.getShardDistribution() db.collection.getShardVersion() db.collection.group() db.collection.insert() db.collection.insertOne() db.collection.insertMany() db.collection.isCapped() db.collection.latencyStats() db.collection.mapReduce() db.collection.reIndex() db.collection.replaceOne() db.collection.remove() db.collection.renameCollection() db.collection.save() db.collection.stats() db.collection.storageSize() db.collection.totalSize() db.collection.totalIndexSize() db.collection.update() db.collection.updateOne() db.collection.updateMany() db.collection.validate() Cursor Methods cursor.addOption() cursor.batchSize() cursor.close() cursor.collation() cursor.comment() cursor.count() cursor.explain() cursor.forEach() cursor.hasNext() cursor.hint() cursor.itcount() cursor.limit() cursor.map() cursor.maxScan() cursor.maxTimeMS() cursor.max() cursor.min() cursor.next() cursor.noCursorTimeout() cursor.objsLeftInBatch() cursor.pretty() cursor.readConcern() cursor.readPref() cursor.returnKey() cursor.showRecordId() cursor.size() cursor.skip() cursor.snapshot() cursor.sort() cursor.tailable() cursor.toArray() Database Methods db.adminCommand() db.cloneCollection() db.cloneDatabase() db.commandHelp() db.copyDatabase() db.createCollection() db.createView() db.currentOp() db.dropDatabase() db.eval() db.fsyncLock() db.fsyncUnlock() db.getCollection() db.getCollectionInfos() db.getCollectionNames() db.getLastError() db.getLastErrorObj() db.getLogComponents() db.getMongo() db.getName() db.getPrevError() db.getProfilingLevel() db.getProfilingStatus() db.getReplicationInfo() db.getSiblingDB() db.help() db.hostInfo() db.isMaster() db.killOp() db.listCommands() db.loadServerScripts() db.logout() db.printCollectionStats() db.printReplicationInfo() db.printShardingStatus() db.printSlaveReplicationInfo() db.repairDatabase() db.resetError() db.runCommand() db.serverBuildInfo() db.serverCmdLineOpts() db.serverStatus() db.setLogLevel() db.setProfilingLevel() db.shutdownServer() db.stats() db.version() db.upgradeCheck() db.upgradeCheckAllDBs() Query Plan Cache Methods db.collection.getPlanCache() PlanCache.help() PlanCache.listQueryShapes() PlanCache.getPlansByQuery() PlanCache.clearPlansByQuery() PlanCache.clear() Bulk Operation Methods Bulk() db.collection.initializeOrderedBulkOp() db.collection.initializeUnorderedBulkOp() Bulk.insert() Bulk.find() Bulk.find.collation() Bulk.find.removeOne() Bulk.find.remove() Bulk.find.replaceOne() Bulk.find.updateOne() Bulk.find.update() Bulk.find.upsert() Bulk.execute() Bulk.getOperations() Bulk.tojson() Bulk.toString() User Management Methods db.auth() db.createUser() db.updateUser() db.changeUserPassword() db.removeUser() db.dropAllUsers() db.dropUser() db.grantRolesToUser() db.revokeRolesFromUser() db.getUser() db.getUsers() Role Management Methods db.createRole() db.updateRole() db.dropRole() db.dropAllRoles() db.grantPrivilegesToRole() db.revokePrivilegesFromRole() db.grantRolesToRole() db.revokeRolesFromRole() db.getRole() db.getRoles() Replication Methods rs.add() rs.addArb() rs.conf() rs.freeze() rs.help() rs.initiate() rs.printReplicationInfo() rs.printSlaveReplicationInfo() rs.reconfig() rs.remove() rs.slaveOk() rs.status() rs.stepDown() rs.syncFrom() Sharding Methods sh._adminCommand() sh.getBalancerLockDetails() sh._checkFullName() sh._checkMongos() sh._lastMigration() sh.addShard() sh.addShardTag() sh.addShardToZone() sh.addTagRange() sh.updateZoneKeyRange() sh.removeTagRange() sh.removeRangeFromZone() sh.disableBalancing() sh.enableBalancing() sh.enableSharding() sh.getBalancerHost() sh.getBalancerState() sh.help() sh.isBalancerRunning() sh.moveChunk() sh.removeShardTag() sh.removeShardFromZone() sh.setBalancerState() sh.shardCollection() sh.splitAt() sh.splitFind() sh.startBalancer() sh.status() sh.stopBalancer() sh.waitForBalancer() sh.waitForBalancerOff() sh.waitForDLock() sh.waitForPingChange() Subprocess Methods clearRawMongoProgramOutput() rawMongoProgramOutput() run() runMongoProgram() runProgram() startMongoProgram() stopMongoProgram() stopMongoProgramByPid() stopMongod() waitMongoProgramOnPort() waitProgram() Object Constructors and Methods Date() UUID() ObjectId ObjectId.getTimestamp() ObjectId.toString() ObjectId.valueOf() WriteResult() WriteResult.hasWriteError() WriteResult.hasWriteConcernError() BulkWriteResult() Connection Methods Mongo.getDB() Mongo.getReadPrefMode() Mongo.getReadPrefTagSet() Mongo.setReadPref() Mongo.setSlaveOk() Mongo() connect() Native Methods cat() version() cd() sleep() copyDbpath() resetDbpath() fuzzFile() getHostName() getMemInfo() hostname() _isWindows() listFiles() load() ls() md5sumFile() mkdir() pwd() quit() _rand() removeFile() setVerboseShell() _srand() MongoDB Package Components mongod mongos mongo mongod.exe mongos.exe mongodump mongorestore bsondump mongooplog mongoimport mongoexport mongostat mongotop mongoperf mongoreplay mongoldap mongofiles Configuration File Options MongoDB Server Parameters MongoDB Limits and Thresholds Explain Results System Collections Connection String URI Format Collation Collation Locales and Default Parameters MongoDB Wire Protocol Log Messages Exit Codes and Statuses Glossary Default MongoDB Port Release Notes Release Notes for MongoDB 3.4 3.4 Changelog Compatibility Changes in MongoDB 3.4 Upgrade a Standalone to 3.4 Upgrade a Replica Set to 3.4 Upgrade a Sharded Cluster to 3.4 Downgrade MongoDB 3.4 to 3.2 Downgrade 3.4 Standalone to 3.2 Downgrade 3.4 Replica Set to 3.2 Downgrade 3.4 Sharded Cluster to 3.2 Release Notes for MongoDB 3.2 3.2 Changelog Compatibility Changes in MongoDB 3.2 JavaScript Changes in MongoDB 3.2 Upgrade MongoDB to 3.2 Downgrade MongoDB from 3.2 Release Notes for MongoDB 3.0 3.0 Changelog Compatibility Changes in MongoDB 3.0 Upgrade MongoDB to 3.0 Upgrade to SCRAM-SHA-1 Downgrade MongoDB from 3.0 Release Notes for MongoDB 2.6 2.6 Changelog Compatibility Changes in MongoDB 2.6 Upgrade MongoDB to 2.6 Upgrade User Authorization Data to 2.6 Format Downgrade MongoDB from 2.6 Release Notes for MongoDB 2.4 2.4 Changelog JavaScript Changes in MongoDB 2.4 Upgrade MongoDB to 2.4 Compatibility and Index Type Changes in MongoDB 2.4 Release Notes for MongoDB 2.2 Release Notes for MongoDB 2.0 Release Notes for MongoDB 1.8 Release Notes for MongoDB 1.6 Release Notes for MongoDB 1.4 Release Notes for MongoDB 1.2.x Introduction to MongoDB \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/crud.html",
      "title": "MongoDB CRUD Operations \u2014 MongoDB Manual 3.4",
      "text": "MongoDB CRUD Operations\u00b6 On this page Create Operations Read Operations Update Operations Delete Operations Bulk Write CRUD operations create, read, update, and delete documents. Create Operations\u00b6 Create or insert operations add new documents to a collection. If the collection does not currently exist, insert operations will create the collection. MongoDB provides the following methods to insert documents into a collection: db.collection.insertOne() New in version 3.2 db.collection.insertMany() New in version 3.2 In MongoDB, insert operations target a single collection. All write operations in MongoDB are atomic on the level of a single document. For examples, see Insert Documents. Read Operations\u00b6 Read operations retrieves documents from a collection; i.e. queries a collection for documents. MongoDB provides the following methods to read documents from a collection: db.collection.find() You can specify query filters or criteria that identify the documents to return. For examples, see: Query Documents Query on Embedded/Nested Documents Query an Array Query an Array of Embedded Documents Update Operations\u00b6 Update operations modify existing documents in a collection. MongoDB provides the following methods to update documents of a collection: db.collection.updateOne() New in version 3.2 db.collection.updateMany() New in version 3.2 db.collection.replaceOne() New in version 3.2 In MongoDB, update operations target a single collection. All write operations in MongoDB are atomic on the level of a single document. You can specify criteria, or filters, that identify the documents to update. These filters use the same syntax as read operations. For examples, see Update Documents. Delete Operations\u00b6 Delete operations remove documents from a collection. MongoDB provides the following methods to delete documents of a collection: db.collection.deleteOne() New in version 3.2 db.collection.deleteMany() New in version 3.2 In MongoDB, delete operations target a single collection. All write operations in MongoDB are atomic on the level of a single document. You can specify criteria, or filters, that identify the documents to remove. These filters use the same syntax as read operations. For examples, see Delete Documents. Bulk Write\u00b6 MongoDB provides the ability to perform write operations in bulk. For details, see Bulk Write Operations. Insert Documents Insert Methods Query Documents Query on Embedded/Nested Documents Query an Array Query an Array of Embedded Documents Project Fields to Return from Query Query for Null or Missing Fields Iterate a Cursor in the mongo Shell Update Documents Update Methods Delete Documents Delete Methods Bulk Write Operations SQL to MongoDB Mapping Chart Read Isolation (Read Concern) Write Acknowledgement (Write Concern) MongoDB CRUD Concepts Atomicity and Transactions Read Isolation, Consistency, and Recency Distributed Queries Distributed Write Operations Perform Two Phase Commits Linearizable Reads via findAndModify Query Plans Query Optimization Evaluate Performance of Current Operations Optimize Query Performance Write Operation Performance Explain Results Analyze Query Performance Tailable Cursors \u2190 mongo Shell Quick Reference Insert Documents \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/index.html",
      "title": "The MongoDB 3.4 Manual \u2014 MongoDB Manual 3.4",
      "text": "The MongoDB 3.4 Manual\u00b6 MongoDB 3.4 Released For summary of new features in MongoDB 3.4, see Release Notes for MongoDB 3.4. New University Course M034: New Features and Tools in MongoDB 3.4. M034 is a continuing education course on MongoDB 3.4. In a series of what will be approximately 16 modules, we will introduce marquee 3.4 features in detail. Upcoming Event MongoDB World\u201817. For more information, see MongoDB World\u201817. Welcome to the MongoDB 3.4 Manual! MongoDB is an open-source, document database designed for ease of development and scaling. The Manual introduces key concepts in MongoDB, presents the query language, and provides operational and administrative considerations and procedures as well as a comprehensive reference section. [1] Getting Started\u00b6 MongoDB provides a Getting Started Guide in the following editions. mongo Shell Edition Node.JS Edition Python Edition C++ Edition Java Edition C# Edition Ruby Edition Once you complete the Getting Started Guide, you may find the following topics useful. Introduction Developers Administrators Reference Introduction to MongoDB Installation Guides Databases and Collections Documents CRUD Operations Aggregation SQL to MongoDB Indexes Production Notes Replica Sets Sharded Clusters MongoDB Security Shell Methods Query Operators Reference Glossary Community\u00b6 Getting involved in the MongoDB community is a great way to build relationships with other talented and like minded engineers, increase awareness for the interesting work that you are doing, and sharpen your skills. To learn about the MongoDB community, see Get Involved with MongoDB. Learning MongoDB\u00b6 In addition to the documentation, there are many ways to learn to use MongoDB. You can: Enroll in a free online course at MongoDB University Browse the archive of MongoDB Presentations Join a local MongoDB User Group (MUG) Attend an upcoming MongoDB event or webinar Read the MongoDB blog Download the Architecture Guide Getting Help\u00b6 If you\u2019re looking for help, you\u2019ll get a quick response to MongoDB questions posted to Stack Overflow or to our mailing list. MongoDB, Inc. also offers commercial support and services. Licensing\u00b6 The manual is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 3.0 United States License For information on MongoDB licensing, see MongoDB Licensing. Additional Resources\u00b6 MongoDB, Inc. The company behind MongoDB. MongoDB Atlas Database as a service. MongoDB Cloud Manager A cloud-based hosted operations management solution for MongoDB. MongoDB Ops Manager Enterprise operations management solution for MongoDB: includes Automation, Backup, and Monitoring. MongoDB Ecosystem The documentation available for the drivers, frameworks, tools, and services for use with MongoDB. [1]The manual is also available as HTML tar.gz and EPUB \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/indexes.html",
      "title": "Indexes \u2014 MongoDB Manual 3.4",
      "text": "Indexes\u00b6 On this page Default _id Index Create an Index Index Types Index Properties Index Use Indexes and Collation Covered Queries Index Intersection Restrictions Additional Considerations Additional Resources Indexes support the efficient execution of queries in MongoDB. Without indexes, MongoDB must perform a collection scan, i.e. scan every document in a collection, to select those documents that match the query statement. If an appropriate index exists for a query, MongoDB can use the index to limit the number of documents it must inspect. Indexes are special data structures [1] that store a small portion of the collection\u2019s data set in an easy to traverse form. The index stores the value of a specific field or set of fields, ordered by the value of the field. The ordering of the index entries supports efficient equality matches and range-based query operations. In addition, MongoDB can return sorted results by using the ordering in the index. The following diagram illustrates a query that selects and orders the matching documents using an index: Fundamentally, indexes in MongoDB are similar to indexes in other database systems. MongoDB defines indexes at the collection level and supports indexes on any field or sub-field of the documents in a MongoDB collection. Default _id Index\u00b6 MongoDB creates a unique index on the _id field during the creation of a collection. The _id index prevents clients from inserting two documents with the same value for the _id field. You cannot drop this index on the _id field. Note In sharded clusters, if you do not use the _id field as the shard key, then your application must ensure the uniqueness of the values in the _id field to prevent errors. This is most-often done by using a standard auto-generated ObjectId. Create an Index\u00b6 To create an index, use db.collection.createIndex() or a similar method from your driver. db.collection.createIndex( <key and index type specification>, <options> ) The db.collection.createIndex() method only creates an index if an index of the same specification does not already exist. [1]MongoDB indexes use a B-tree data structure. Index Types\u00b6 MongoDB provides a number of different index types to support specific types of data and queries. Single Field\u00b6 In addition to the MongoDB-defined _id index, MongoDB supports the creation of user-defined ascending/descending indexes on a single field of a document. For a single-field index and sort operations, the sort order (i.e. ascending or descending) of the index key does not matter because MongoDB can traverse the index in either direction. See Single Field Indexes and Sort with a Single Field Index for more information on single-field indexes. Compound Index\u00b6 MongoDB also supports user-defined indexes on multiple fields, i.e. compound indexes. The order of fields listed in a compound index has significance. For instance, if a compound index consists of { userid: 1, score: -1 }, the index sorts first by userid and then, within each userid value, sorts by score. For compound indexes and sort operations, the sort order (i.e. ascending or descending) of the index keys can determine whether the index can support a sort operation. See Sort Order for more information on the impact of index order on results in compound indexes. See Compound Indexes and Sort on Multiple Fields for more information on compound indexes. Multikey Index\u00b6 MongoDB uses multikey indexes to index the content stored in arrays. If you index a field that holds an array value, MongoDB creates separate index entries for every element of the array. These multikey indexes allow queries to select documents that contain arrays by matching on element or elements of the arrays. MongoDB automatically determines whether to create a multikey index if the indexed field contains an array value; you do not need to explicitly specify the multikey type. See Multikey Indexes and Multikey Index Bounds for more information on multikey indexes. Geospatial Index\u00b6 To support efficient queries of geospatial coordinate data, MongoDB provides two special indexes: 2d indexes that uses planar geometry when returning results and 2dsphere indexes that use spherical geometry to return results. See 2d Index Internals for a high level introduction to geospatial indexes. Text Indexes\u00b6 MongoDB provides a text index type that supports searching for string content in a collection. These text indexes do not store language-specific stop words (e.g. \u201cthe\u201d, \u201ca\u201d, \u201cor\u201d) and stem the words in a collection to only store root words. See Text Indexes for more information on text indexes and search. Hashed Indexes\u00b6 To support hash based sharding, MongoDB provides a hashed index type, which indexes the hash of the value of a field. These indexes have a more random distribution of values along their range, but only support equality matches and cannot support range-based queries. Index Properties\u00b6 Unique Indexes\u00b6 The unique property for an index causes MongoDB to reject duplicate values for the indexed field. Other than the unique constraint, unique indexes are functionally interchangeable with other MongoDB indexes. Partial Indexes\u00b6 New in version 3.2. Partial indexes only index the documents in a collection that meet a specified filter expression. By indexing a subset of the documents in a collection, partial indexes have lower storage requirements and reduced performance costs for index creation and maintenance. Partial indexes offer a superset of the functionality of sparse indexes and should be preferred over sparse indexes. Sparse Indexes\u00b6 The sparse property of an index ensures that the index only contain entries for documents that have the indexed field. The index skips documents that do not have the indexed field. You can combine the sparse index option with the unique index option to reject documents that have duplicate values for a field but ignore documents that do not have the indexed key. TTL Indexes\u00b6 TTL indexes are special indexes that MongoDB can use to automatically remove documents from a collection after a certain amount of time. This is ideal for certain types of information like machine generated event data, logs, and session information that only need to persist in a database for a finite amount of time. See: Expire Data from Collections by Setting TTL for implementation instructions. Index Use\u00b6 Indexes can improve the efficiency of read operations. The Analyze Query Performance tutorial provides an example of the execution statistics of a query with and without an index. For information on how MongoDB chooses an index to use, see query optimizer. Indexes and Collation\u00b6 To use an index for string comparisons, an operation must also specify the same collation. That is, an index with a collation cannot support an operation that performs string comparisons on the indexed fields if the operation specifies a different collation. For example, the collection myColl has an index on a string field category with the collation locale \"fr\". db.myColl.createIndex( { category: 1 }, { collation: { locale: \"fr\" } } ) The following query operation, which specifies the same collation as the index, can use the index: db.myColl.find( { category: \"cafe\" } ).collation( { locale: \"fr\" } ) However, the following query operation, which by default uses the \u201csimple\u201d binary collator, cannot use the index: db.myColl.find( { category: \"cafe\" } ) For a compound index where the index prefix keys are not strings, arrays, and embedded documents, an operation that specifies a different collation can still use the index to support comparisons on the index prefix keys. For example, the collection myColl has a compound index on the numeric fields score and price and the string field category; the index is created with the collation locale \"fr\" for string comparisons: db.myColl.createIndex( { score: 1, price: 1, category: 1 }, { collation: { locale: \"fr\" } } ) The following operations, which use \"simple\" binary collation for string comparisons, can use the index: db.myColl.find( { score: 5 } ).sort( { price: 1 } ) db.myColl.find( { score: 5, price: { $gt: NumberDecimal( \"10\" ) } } ).sort( { price: 1 } ) The following operation, which uses \"simple\" binary collation for string comparisons on the indexed category field, can use the index to fulfill only the score: 5 portion of the query: db.myColl.find( { score: 5, category: \"cafe\" } ) Covered Queries\u00b6 When the query criteria and the projection of a query include only the indexed fields, MongoDB will return results directly from the index without scanning any documents or bringing documents into memory. These covered queries can be very efficient. For more information on covered queries, see Covered Query. Index Intersection\u00b6 New in version 2.6. MongoDB can use the intersection of indexes to fulfill queries. For queries that specify compound query conditions, if one index can fulfill a part of a query condition, and another index can fulfill another part of the query condition, then MongoDB can use the intersection of the two indexes to fulfill the query. Whether the use of a compound index or the use of an index intersection is more efficient depends on the particular query and the system. For details on index intersection, see Index Intersection. Restrictions\u00b6 Certain restrictions apply to indexes, such as the length of the index keys or the number of indexes per collection. See Index Limitations for details. Additional Considerations\u00b6 Although indexes can improve query performances, indexes also present some operational considerations. See Operational Considerations for Indexes for more information. If your collection holds a large amount of data, and your application needs to be able to access the data while building the index, consider building the index in the background, as described in Background Construction. To build or rebuild indexes for a replica set, see Build Indexes on Replica Sets. Some drivers may specify indexes, using NumberLong(1) rather than 1 as the specification. This does not have any affect on the resulting index. Single Field Indexes Compound Indexes Multikey Indexes Multikey Index Bounds Text Indexes Specify a Language for Text Index Specify Name for text Index Control Search Results with Weights Limit the Number of Entries Scanned 2dsphere Indexes Find Restaurants with Geospatial Queries Query a 2dsphere Index GeoJSON Objects 2d Indexes Create a 2d Index Query a 2d Index 2d Index Internals Calculate Distance Using Spherical Geometry Hashed Indexes Index Properties TTL Indexes Expire Data from Collections by Setting TTL Unique Indexes Partial Indexes Case Insensitive Indexes Sparse Indexes Index Build Operations Build Indexes on Replica Sets Index Intersection Manage Indexes Measure Index Use Indexing Strategies Create Indexes to Support Your Queries Use Indexes to Sort Query Results Ensure Indexes Fit in RAM Create Queries that Ensure Selectivity Indexing Reference Additional Resources\u00b6 Quick Reference Cards \u2190 Troubleshoot SNMP Single Field Indexes \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/installation.html",
      "title": "Install MongoDB \u2014 MongoDB Manual 3.4",
      "text": "Install MongoDB\u00b6 On this page Supported Platforms Tutorials Additional Resources This section of the manual contains tutorials on installation of MongoDB. Supported Platforms\u00b6 Changed in version 3.4: MongoDB no longer supports 32-bit x86 platforms. x86_64\u00b6 Platform 3.4 Community & Enterprise 3.2 Community & Enterprise 3.0 Community & Enterprise Amazon Linux 2013.03 and later \u2713 \u2713 \u2713 Debian 7 \u2713 \u2713 \u2713 Debian 8 \u2713 \u2713 RHEL/CentOS 6.2 and later \u2713 \u2713 \u2713 RHEL/CentOS 7.0 and later \u2713 \u2713 \u2713 SLES 11 \u2713 \u2713 \u2713 SLES 12 \u2713 Solaris 11 64-bit Community only Community only Community only Ubuntu 12.04 \u2713 \u2713 \u2713 Ubuntu 14.04 \u2713 \u2713 \u2713 Ubuntu 16.04 \u2713 \u2713 Windows Server 2008R2 and later \u2713 \u2713 \u2713 Windows Vista and later \u2713 \u2713 \u2713 OS X 10.7 and later \u2713 \u2713 ARM64\u00b6 Platform 3.4 Community & Enterprise Ubuntu 16.04 \u2713 PPC64LE (MongoDB Enterprise Edition)\u00b6 Platform 3.4 Enterprise RHEL/CentOS 7.1 \u2713 Ubuntu 16.04 \u2713 s390x (MongoDB Enterprise Edition)\u00b6 Platform 3.4 Enterprise RHEL/CentOS 7.2 \u2713 SLES 11 \u2713 SLES 12 \u2713 Ubuntu 16.04 \u2713 Tutorials\u00b6 MongoDB Community Edition\u00b6 Install on Linux Install MongoDB Community Edition and required dependencies on Linux. Install on OS X Install MongoDB Community Edition on OS X systems from Homebrew packages or from MongoDB archives. Install on Windows Install MongoDB Community Edition on Windows systems and optionally start MongoDB as a Windows service. MongoDB Enterprise\u00b6 Install on Linux Install the official builds of MongoDB Enterprise on Linux-based systems. Install on OS X Install the official build of MongoDB Enterprise on OS X Install on Windows Install MongoDB Enterprise on Windows using the .msi installer. Install MongoDB Community Edition Install on Linux Install on Red Hat Install on SUSE Install on Amazon Install on Ubuntu Install on Debian Install From Tarball Install on OS X Install on Windows Install MongoDB Enterprise Install on Linux Install on Red Hat Install on Ubuntu Install on Debian Install on SUSE Install on Amazon Install From Tarball Install on OS X Install on Windows Verify Integrity of MongoDB Packages Additional Resources\u00b6 MongoDB Atlas: A cloud-hosted database service for running, monitoring, and maintaining MongoDB deployments. Install MongoDB using MongoDB Cloud Manager Create a New MongoDB Deployment with Ops Manager: Ops Manager is an on-premise solution available in MongoDB Enterprise Advanced. MongoDB CRUD Operations Data Models \u2190 MongoDB Extended JSON Install MongoDB Community Edition \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/analyzing-mongodb-performance.html",
      "title": "MongoDB Performance \u2014 MongoDB Manual 3.4",
      "text": "Administration > MongoDB Performance MongoDB Performance\u00b6 On this page Locking Performance Memory and the MMAPv1 Storage Engine Number of Connections Database Profiling Additional Resources As you develop and operate applications with MongoDB, you may need to analyze the performance of the application and its database. When you encounter degraded performance, it is often a function of database access strategies, hardware availability, and the number of open database connections. Some users may experience performance limitations as a result of inadequate or inappropriate indexing strategies, or as a consequence of poor schema design patterns. Locking Performance discusses how these can impact MongoDB\u2019s internal locking. Performance issues may indicate that the database is operating at capacity and that it is time to add additional capacity to the database. In particular, the application\u2019s working set should fit in the available physical memory. See Memory and the MMAPv1 Storage Engine for more information on the working set. In some cases performance issues may be temporary and related to abnormal traffic load. As discussed in Number of Connections, scaling can help relax excessive traffic. Database Profiling can help you to understand what operations are causing degradation. Locking Performance\u00b6 MongoDB uses a locking system to ensure data set consistency. If certain operations are long-running or a queue forms, performance will degrade as requests and operations wait for the lock. Lock-related slowdowns can be intermittent. To see if the lock has been affecting your performance, refer to the locks section and the globalLock section of the serverStatus output. Dividing locks.timeAcquiringMicros by locks.acquireWaitCount can give an approximate average wait time for a particular lock mode. locks.deadlockCount provide the number of times the lock acquisitions encountered deadlocks. If globalLock.currentQueue.total is consistently high, then there is a chance that a large number of requests are waiting for a lock. This indicates a possible concurrency issue that may be affecting performance. If globalLock.totalTime is high relative to uptime, the database has existed in a lock state for a significant amount of time. Long queries can result from ineffective use of indexes; non-optimal schema design; poor query structure; system architecture issues; or insufficient RAM resulting in page faults and disk reads. Memory and the MMAPv1 Storage Engine\u00b6 Memory Use\u00b6 With the MMAPv1 storage engine, MongoDB uses memory-mapped files to store data. Given a data set of sufficient size, the mongod process will allocate all available memory on the system for its use. While this is intentional and aids performance, the memory mapped files make it difficult to determine if the amount of RAM is sufficient for the data set. The memory usage statuses metrics of the serverStatus output can provide insight into MongoDB\u2019s memory use. The mem.resident field provides the amount of resident memory in use. If this exceeds the amount of system memory and there is a significant amount of data on disk that isn\u2019t in RAM, you may have exceeded the capacity of your system. You can inspect mem.mapped to check the amount of mapped memory that mongod is using. If this value is greater than the amount of system memory, some operations will require a page faults to read data from disk. Page Faults\u00b6 With the MMAPv1 storage engine, page faults can occur as MongoDB reads from or writes data to parts of its data files that are not currently located in physical memory. In contrast, operating system page faults happen when physical memory is exhausted and pages of physical memory are swapped to disk. MongoDB reports its triggered page faults as the total number of page faults in one second. To check for page faults, see the extra_info.page_faults value in the serverStatus output. Rapid increases in the MongoDB page fault counter may indicate that the server has too little physical memory. Page faults also can occur while accessing large data sets or scanning an entire collection. A single page fault completes quickly and is not problematic. However, in aggregate, large volumes of page faults typically indicate that MongoDB is reading too much data from disk. MongoDB can often \u201cyield\u201d read locks after a page fault, allowing other database processes to read while mongod loads the next page into memory. Yielding the read lock following a page fault improves concurrency, and also improves overall throughput in high volume systems. Increasing the amount of RAM accessible to MongoDB may help reduce the frequency of page faults. If this is not possible, you may want to consider deploying a sharded cluster or adding shards to your deployment to distribute load among mongod instances. See What are page faults? for more information. Number of Connections\u00b6 In some cases, the number of connections between the applications and the database can overwhelm the ability of the server to handle requests. The following fields in the serverStatus document can provide insight: globalLock.activeClients contains a counter of the total number of clients with active operations in progress or queued. connections is a container for the following two fields: connections.current the total number of current clients that connect to the database instance. connections.available the total number of unused connections available for new clients. If there are numerous concurrent application requests, the database may have trouble keeping up with demand. If this is the case, then you will need to increase the capacity of your deployment. For read-heavy applications, increase the size of your replica set and distribute read operations to secondary members. For write-heavy applications, deploy sharding and add one or more shards to a sharded cluster to distribute load among mongod instances. Spikes in the number of connections can also be the result of application or driver errors. All of the officially supported MongoDB drivers implement connection pooling, which allows clients to use and reuse connections more efficiently. Extremely high numbers of connections, particularly without corresponding workload is often indicative of a driver or other configuration error. Unless constrained by system-wide limits, MongoDB has no limit on incoming connections. On Unix-based systems, you can modify system limits using the ulimit command, or by editing your system\u2019s /etc/sysctl file. See UNIX ulimit Settings for more information. Database Profiling\u00b6 MongoDB\u2019s \u201cProfiler\u201d is a database profiling system that can help identify inefficient queries and operations. The following profiling levels are available: Level Setting 0 Off. No profiling 1 On. Only includes \u201cslow\u201d operations 2 On. Includes all operations Enable the profiler by setting the profile value using the following command in the mongo shell: db.setProfilingLevel(1) The slowOpThresholdMs setting defines what constitutes a \u201cslow\u201d operation. To set the threshold above which the profiler considers operations \u201cslow\u201d (and thus, included in the level 1 profiling data), you can configure slowOpThresholdMs at runtime as an argument to the db.setProfilingLevel() operation. See The documentation of db.setProfilingLevel() for more information. By default, mongod records all \u201cslow\u201d queries to its log, as defined by slowOpThresholdMs. Note Because the database profiler can negatively impact performance, only enable profiling for strategic intervals and as minimally as possible on production systems. You may enable profiling on a per-mongod basis. This setting will not propagate across a replica set or sharded cluster. You can view the output of the profiler in the system.profile collection of your database by issuing the show profile command in the mongo shell, or with the following operation: db.system.profile.find( { millis : { $gt : 100 } } ) This returns all operations that lasted longer than 100 milliseconds. Ensure that the value specified here (100, in this example) is above the slowOpThresholdMs threshold. You must use the $query operator to access the query field of documents within system.profile. Database Profiler Database Profiler Output Disable Transparent Huge Pages (THP) UNIX ulimit Settings Additional Resources\u00b6 MongoDB Ops Optimization Consulting Package \u2190 Development Checklist Database Profiler \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/backup-sharded-clusters.html",
      "title": "Backup and Restore Sharded Clusters \u2014 MongoDB Manual 3.4",
      "text": "Administration > MongoDB Backup Methods > Backup and Restore Sharded Clusters Backup and Restore Sharded Clusters\u00b6 The following tutorials describe backup and restoration for sharded clusters: Back Up a Sharded Cluster with File System Snapshots Use file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools. Back Up a Sharded Cluster with Database Dumps Create backups using mongodump to back up each component in the cluster individually. Schedule Backup Window for Sharded Clusters Limit the operation of the cluster balancer to provide a window for regular backup operations. Restore a Sharded Cluster An outline of the procedure and consideration for restoring an entire sharded cluster from backup. Back Up a Sharded Cluster with File System Snapshots Back Up a Sharded Cluster with Database Dumps Schedule Backup Window for Sharded Clusters Restore a Sharded Cluster \u2190 Restore a Replica Set from MongoDB Backups Back Up a Sharded Cluster with File System Snapshots \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/configuration-and-maintenance.html",
      "title": "Configuration and Maintenance \u2014 MongoDB Manual 3.4",
      "text": "Administration > Configuration and Maintenance Configuration and Maintenance\u00b6 This section describes routine management operations, including updating your MongoDB deployment\u2019s configuration. Run-time Database Configuration Outlines common MongoDB configurations and examples of best-practice configurations for common use cases. Upgrade to the Latest Revision of MongoDB Introduces the basic process for upgrading a MongoDB deployment between different minor release versions. Manage mongod Processes Start, configure, and manage running mongod process. Terminate Running Operations Stop in progress MongoDB client operations using db.killOp() and maxTimeMS(). Rotate Log Files Archive the current log files and start new ones. Run-time Database Configuration Upgrade to the Latest Revision of MongoDB Manage mongod Processes Terminate Running Operations Rotate Log Files \u2190 UNIX ulimit Settings Run-time Database Configuration \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/configuration.html",
      "title": "Run-time Database Configuration \u2014 MongoDB Manual 3.4",
      "text": "Administration > Configuration and Maintenance > Run-time Database Configuration Run-time Database Configuration\u00b6 On this page Configure the Database Security Considerations Replication and Sharding Configuration Run Multiple Database Instances on the Same System Diagnostic Configurations The command line and configuration file interfaces provide MongoDB administrators with a large number of options and settings for controlling the operation of the database system. This document provides an overview of common configurations and examples of best-practice configurations for common use cases. While both interfaces provide access to the same collection of options and settings, this document primarily uses the configuration file interface. If you run MongoDB using a init script or if you installed from a package for your operating system, you likely already have a configuration file located at /etc/mongod.conf. Confirm this by checking the contents of the /etc/init.d/mongod or /etc/rc.d/mongod script to ensure that the init scripts start the mongod with the appropriate configuration file. To start a MongoDB instance using this configuration file, issue a command in the following form: mongod --config /etc/mongod.conf mongod -f /etc/mongod.conf Modify the values in the /etc/mongod.conf file on your system to control the configuration of your database instance. Configure the Database\u00b6 Consider the following basic configuration which uses the YAML format: processManagement: fork: true net: bindIp: 127.0.0.1 port: 27017 storage: dbPath: /srv/mongodb systemLog: destination: file path: \"/var/log/mongodb/mongod.log\" logAppend: true storage: journal: enabled: true Or, if using the older .ini configuration file format: fork = true bind_ip = 127.0.0.1 port = 27017 quiet = true dbpath = /srv/mongodb logpath = /var/log/mongodb/mongod.log logappend = true journal = true For most standalone servers, this is a sufficient base configuration. It makes several assumptions, but consider the following explanation: fork is true, which enables a daemon mode for mongod, which detaches (i.e. \u201cforks\u201d) the MongoDB from the current session and allows you to run the database as a conventional server. bindIp is 127.0.0.1, which forces the server to only listen for requests on the localhost IP. Only bind to secure interfaces that the application-level systems can access with access control provided by system network filtering (i.e. \u201cfirewall\u201d). New in version 2.6: mongod installed from official .deb and .rpm packages have the bind_ip configuration set to 127.0.0.1 by default. port is 27017, which is the default MongoDB port for database instances. MongoDB can bind to any port. You can also filter access based on port using network filtering tools. Note UNIX-like systems require superuser privileges to attach processes to ports lower than 1024. quiet is true. This disables all but the most critical entries in output/log file, and is not recommended for production systems. If you do set this option, you can use setParameter to modify this setting during run time. dbPath is /srv/mongodb, which specifies where MongoDB will store its data files. /srv/mongodb and /var/lib/mongodb are popular locations. The user account that mongod runs under will need read and write access to this directory. systemLog.path is /var/log/mongodb/mongod.log which is where mongod will write its output. If you do not set this value, mongod writes all output to standard output (e.g. stdout.) logAppend is true, which ensures that mongod does not overwrite an existing log file following the server start operation. storage.journal.enabled is true, which enables journaling. Journaling ensures single instance write-durability. 64-bit builds of mongod enable journaling by default. Thus, this setting may be redundant. Given the default configuration, some of these values may be redundant. However, in many situations explicitly stating the configuration increases overall system intelligibility. Security Considerations\u00b6 The following collection of configuration options are useful for limiting access to a mongod instance. Consider the following settings, shown in both YAML and older configuration file format: In YAML format security: authorization: enabled net: bindIp: 127.0.0.1,10.8.0.10,192.168.4.24 Or, if using the older older configuration file format: bind_ip = 127.0.0.1,10.8.0.10,192.168.4.24 auth = true Consider the following explanation for these configuration decisions: \u201cbindIp\u201d has three values: 127.0.0.1, the localhost interface; 10.8.0.10, a private IP address typically used for local networks and VPN interfaces; and 192.168.4.24, a private network interface typically used for local networks. Because production MongoDB instances need to be accessible from multiple database servers, it is important to bind MongoDB to multiple interfaces that are accessible from your application servers. At the same time it\u2019s important to limit these interfaces to interfaces controlled and protected at the network layer. \u201cauthorization\u201d is true enables the authorization system within MongoDB. If enabled you will need to log in by connecting over the localhost interface for the first time to create user credentials. See also Security Replication and Sharding Configuration\u00b6 Replication Configuration\u00b6 Replica set configuration is straightforward, and only requires that the replSetName have a value that is consistent among all members of the set. Consider the following: In YAML format replication: replSetName: set0 Or, if using the older configuration file format: replSet = set0 Use descriptive names for sets. Once configured, use the mongo shell to add hosts to the replica set. See also Replica set reconfiguration. To enable authentication for the replica set, add the following keyFile option: In YAML format security: keyFile: /srv/mongodb/keyfile Or, if using the older configuration file format: keyFile = /srv/mongodb/keyfile Setting keyFile enables authentication and specifies a key file for the replica set member use to when authenticating to each other. The content of the key file is arbitrary, but must be the same on all members of the replica set and mongos instances that connect to the set. The keyfile must be less than one kilobyte in size and may only contain characters in the base64 set and the file must not have group or \u201cworld\u201d permissions on UNIX systems. See also The Replica Set Security section for information on configuring authentication with replica sets. The Replication document for more information on replication in MongoDB and replica set configuration in general. Sharding Configuration\u00b6 Sharding requires mongod instances with different mongod configurations for the config servers and the shards. The config servers store the cluster\u2019s metadata, while the shards store the data. To configure the config server mongod instances, in the configuration file, specify configsvr for the sharding.clusterRole setting. Changed in version 3.4: Starting in version 3.4, MongoDB removes support for mirrored config servers and config servers must be deployed as a replica set. See Upgrade Config Servers to Replica Set. sharding: clusterRole: configsvr net: bindIp: 10.8.0.12 port: 27001 replication: replSetName: csRS To deploy config servers as a replica set, the config servers must run the WiredTiger Storage Engine. Initiate the replica set and add members. To configure the shard mongod instances, specify shardsvr for the sharding.clusterRole setting, and if running as a replica set, the replica set name: sharding: clusterRole: shardsvr replication: replSetName: shardA If running as a replica set, initiate the shard replica set and add members. For the router (i.e. mongos), configure at least one mongos process with the following setting: sharding: configDB: csRS/10.8.0.12:27001 You can specify additional members of the config server replica set by specifying hostnames and ports in the form of a comma separated list after the replica set name. See also The Sharding section of the manual for more information on sharding and cluster configuration. Run Multiple Database Instances on the Same System\u00b6 In many cases running multiple instances of mongod on a single system is not recommended. On some types of deployments [1] and for testing purposes you may need to run more than one mongod on a single system. In these cases, use a base configuration for each instance, but consider the following configuration values: In YAML format: storage: dbPath: /srv/mongodb/db0/ processManagement: pidFilePath: /srv/mongodb/db0.pid Or, if using the older configuration file format: dbpath = /srv/mongodb/db0/ pidfilepath = /srv/mongodb/db0.pid The dbPath value controls the location of the mongod instance\u2019s data directory. Ensure that each database has a distinct and well labeled data directory. The pidFilePath controls where mongod process places it\u2019s process id file. As this tracks the specific mongod file, it is crucial that file be unique and well labeled to make it easy to start and stop these processes. Create additional init scripts and/or adjust your existing MongoDB configuration and init script as needed to control these processes. [1]Single-tenant systems with SSD or other high performance disks may provide acceptable performance levels for multiple mongod instances. Additionally, you may find that multiple databases with small working sets may function acceptably on a single system. Diagnostic Configurations\u00b6 The following configuration options control various mongod behaviors for diagnostic purposes: operationProfiling.mode sets the database profiler level. The profiler is not active by default because of the possible impact on the profiler itself on performance. Unless this setting is on, queries are not profiled. operationProfiling.slowOpThresholdMs configures the threshold which determines whether a query is \u201cslow\u201d for the purpose of the logging system and the profiler. The default value is 100 milliseconds. Set a lower value if the database profiler does not return useful results or a higher value to only log the longest running queries. systemLog.verbosity controls the amount of logging output that mongod write to the log. Only use this option if you are experiencing an issue that is not reflected in the normal logging level. Changed in version 3.0: You can also specify verbosity level for specific components using the systemLog.component.<name>.verbosity setting. For the available components, see component verbosity settings. For more information, see also Database Profiling and MongoDB Performance. \u2190 Configuration and Maintenance Upgrade to the Latest Revision of MongoDB \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/install-community.html",
      "title": "Install MongoDB Community Edition \u2014 MongoDB Manual 3.4",
      "text": "Install MongoDB > Install MongoDB Community Edition Install MongoDB Community Edition\u00b6 These documents provide instructions to install MongoDB Community Edition. Install on Linux Install MongoDB Community Edition and required dependencies on Linux. Install on OS X Install MongoDB Community Edition on OS X systems from Homebrew packages or from MongoDB archives. Install on Windows Install MongoDB Community Edition on Windows systems and optionally start MongoDB as a Windows service. Install on Linux Install on Red Hat Install on SUSE Install on Amazon Install on Ubuntu Install on Debian Install From Tarball Install on OS X Install on Windows \u2190 Install MongoDB Install MongoDB Community Edition on Linux \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/install-enterprise-linux.html",
      "title": "Install MongoDB Enterprise on Linux \u2014 MongoDB Manual 3.4",
      "text": "Install MongoDB > Install MongoDB Enterprise > Install MongoDB Enterprise on Linux Install MongoDB Enterprise on Linux\u00b6 Install on Red Hat Install MongoDB Enterprise and required dependencies on Red Hat Enterprise or CentOS Systems using packages. Install on Ubuntu Install MongoDB Enterprise and required dependencies on Ubuntu Linux Systems using packages. Install on Debian Install MongoDB Enterprise and required dependencies on Debian Linux Systems using packages. Install on SUSE Install MongoDB Enterprise and required dependencies on SUSE Enterprise Linux. Install on Amazon Install MongoDB Enterprise and required dependencies on Amazon Linux AMI. Install From Tarball Install MongoDB Enterprise from a tarball. Install on Red Hat Install on Ubuntu Install on Debian Install on SUSE Install on Amazon Install From Tarball \u2190 Install MongoDB Enterprise Install MongoDB Enterprise on Red Hat Enterprise or CentOS \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/install-enterprise.html",
      "title": "Install MongoDB Enterprise \u2014 MongoDB Manual 3.4",
      "text": "Install MongoDB > Install MongoDB Enterprise Install MongoDB Enterprise\u00b6 These documents provide instructions to install MongoDB Enterprise. MongoDB Enterprise is available for MongoDB Enterprise subscribers and includes several additional features including support for SNMP monitoring, LDAP authentication, Kerberos authentication, and System Event Auditing. Install on Linux Install the official builds of MongoDB Enterprise on Linux-based systems. Install on OS X Install the official build of MongoDB Enterprise on OS X Install on Windows Install MongoDB Enterprise on Windows using the .msi installer. Install on Linux Install on Red Hat Install on Ubuntu Install on Debian Install on SUSE Install on Amazon Install From Tarball Install on OS X Install on Windows \u2190 Install MongoDB Community Edition on Windows Install MongoDB Enterprise on Linux \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/install-on-linux.html",
      "title": "Install MongoDB Community Edition on Linux \u2014 MongoDB Manual 3.4",
      "text": "Install MongoDB > Install MongoDB Community Edition > Install MongoDB Community Edition on Linux Install MongoDB Community Edition on Linux\u00b6 On this page Recommended Manual Installation These documents provide instructions to install MongoDB Community Edition for various Linux systems. Recommended\u00b6 For the best installation experience, MongoDB provides packages for popular Linux distributions. These packages, which support specific platforms and provide improved performance and TLS/SSL support, are the preferred way to run MongoDB. The following guides detail the installation process for these systems: Install on Red Hat Install MongoDB Community Edition on Red Hat Enterprise and related Linux systems using .rpm packages. Install on SUSE Install MongoDB Community Edition on SUSE Linux systems using .rpm packages. Install on Amazon Install MongoDB Community Edition on Amazon Linux AMI systems using .rpm packages. Install on Ubuntu Install MongoDB Community Edition on Ubuntu Linux systems using .deb packages. Install on Debian Install MongoDB Community Edition on Debian systems using .deb packages. For systems without supported packages, refer to the Manual Installation tutorial. Manual Installation\u00b6 For Linux systems without supported packages, MongoDB provides a generic Linux release. These versions of MongoDB don\u2019t include TLS/SSL, and may not perform as well as the targeted packages, but are compatible on most contemporary Linux systems. See the following guides for installation: Install From Tarball Install MongoDB Community Edition on other Linux systems from MongoDB archives. Install on Red Hat Install on SUSE Install on Amazon Install on Ubuntu Install on Debian Install From Tarball \u2190 Install MongoDB Community Edition Install MongoDB Community Edition on Red Hat Enterprise or CentOS Linux \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/monitoring.html",
      "title": "Monitoring for MongoDB \u2014 MongoDB Manual 3.4",
      "text": "Administration > Monitoring for MongoDB Monitoring for MongoDB\u00b6 On this page Monitoring Strategies MongoDB Reporting Tools Process Logging Diagnosing Performance Issues Replication and Monitoring Sharding and Monitoring Additional Resources Monitoring is a critical component of all database administration. A firm grasp of MongoDB\u2019s reporting will allow you to assess the state of your database and maintain your deployment without crisis. Additionally, a sense of MongoDB\u2019s normal operational parameters will allow you to diagnose problems before they escalate to failures. This document presents an overview of the available monitoring utilities and the reporting statistics available in MongoDB. It also introduces diagnostic strategies and suggestions for monitoring replica sets and sharded clusters. Note MongoDB Atlas is a cloud-hosted database-as-a-service. MongoDB Cloud Manager, a hosted service, and Ops Manager, an on-premise solution, provide monitoring, backup, and automation of MongoDB instances. For documentation, see Atlas documentation, the MongoDB Cloud Manager documentation and Ops Manager documentation Monitoring Strategies\u00b6 There are three methods for collecting data about the state of a running MongoDB instance: First, there is a set of utilities distributed with MongoDB that provides real-time reporting of database activities. Second, database commands return statistics regarding the current database state with greater fidelity. Third, MongoDB Atlas is a cloud-hosted database-as-a-service for running, monitoring, and maintaining MongoDB deployments. MongoDB Cloud Manager, a hosted service, and Ops Manager, an on-premise solution available in MongoDB Enterprise Advanced, provide monitoring to collect data from running MongoDB deployments as well as providing visualization and alerts based on that data. Each strategy can help answer different questions and is useful in different contexts. These methods are complementary. MongoDB Reporting Tools\u00b6 This section provides an overview of the reporting methods distributed with MongoDB. It also offers examples of the kinds of questions that each method is best suited to help you address. Utilities\u00b6 The MongoDB distribution includes a number of utilities that quickly return statistics about instances\u2019 performance and activity. Typically, these are most useful for diagnosing issues and assessing normal operation. mongostat\u00b6 mongostat captures and returns the counts of database operations by type (e.g. insert, query, update, delete, etc.). These counts report on the load distribution on the server. Use mongostat to understand the distribution of operation types and to inform capacity planning. See the mongostat manual for details. mongotop\u00b6 mongotop tracks and reports the current read and write activity of a MongoDB instance, and reports these statistics on a per collection basis. Use mongotop to check if your database activity and use match your expectations. See the mongotop manual for details. HTTP Console\u00b6 Deprecated since version 3.2: HTTP interface for MongoDB MongoDB provides a web interface that exposes diagnostic and monitoring information in a simple web page. The web interface is accessible at localhost:<port>, where the <port> number is 1000 more than the mongod port . For example, if a locally running mongod is using the default port 27017, access the HTTP console at http://localhost:28017. Commands\u00b6 MongoDB includes a number of commands that report on the state of the database. These data may provide a finer level of granularity than the utilities discussed above. Consider using their output in scripts and programs to develop custom alerts, or to modify the behavior of your application in response to the activity of your instance. The db.currentOp method is another useful tool for identifying the database instance\u2019s in-progress operations. serverStatus\u00b6 The serverStatus command, or db.serverStatus() from the shell, returns a general overview of the status of the database, detailing disk usage, memory use, connection, journaling, and index access. The command returns quickly and does not impact MongoDB performance. serverStatus outputs an account of the state of a MongoDB instance. This command is rarely run directly. In most cases, the data is more meaningful when aggregated, as one would see with monitoring tools including MongoDB Cloud Manager and Ops Manager. Nevertheless, all administrators should be familiar with the data provided by serverStatus. dbStats\u00b6 The dbStats command, or db.stats() from the shell, returns a document that addresses storage use and data volumes. The dbStats reflect the amount of storage used, the quantity of data contained in the database, and object, collection, and index counters. Use this data to monitor the state and storage capacity of a specific database. This output also allows you to compare use between databases and to determine the average document size in a database. collStats\u00b6 The collStats or db.collection.stats() from the shell that provides statistics that resemble dbStats on the collection level, including a count of the objects in the collection, the size of the collection, the amount of disk space used by the collection, and information about its indexes. replSetGetStatus\u00b6 The replSetGetStatus command (rs.status() from the shell) returns an overview of your replica set\u2019s status. The replSetGetStatus document details the state and configuration of the replica set and statistics about its members. Use this data to ensure that replication is properly configured, and to check the connections between the current host and the other members of the replica set. Third Party Tools\u00b6 A number of third party monitoring tools have support for MongoDB, either directly, or through their own plugins. Self Hosted Monitoring Tools\u00b6 These are monitoring tools that you must install, configure and maintain on your own servers. Most are open source. Tool Plugin Description Ganglia mongodb-ganglia Python script to report operations per second, memory usage, btree statistics, master/slave status and current connections. Ganglia gmond_python_modules Parses output from the serverStatus and replSetGetStatus commands. Motop None Realtime monitoring tool for MongoDB servers. Shows current operations ordered by durations every second. mtop None A top like tool. Munin mongo-munin Retrieves server statistics. Munin mongomon Retrieves collection statistics (sizes, index sizes, and each (configured) collection count for one DB). Munin munin-plugins Ubuntu PPA Some additional munin plugins not in the main distribution. Nagios nagios-plugin-mongodb A simple Nagios check script, written in Python. SPM Performance Monitoring MongoDB Docker Agent Monitoring, Anomaly Detection and Alerting SPM monitors all key MongoDB metrics together with infrastructure incl. Docker and other application metrics e.g. Node.js, Java, NGINX, Apache, HAProxy or Elasticsearch. SPM is available On Premises and in the Cloud (SaaS) and provides correlation of metrics and logs. Also consider dex, an index and query analyzing tool for MongoDB that compares MongoDB log files and indexes to make indexing recommendations. See also Ops Manager, an on-premise solution available in MongoDB Enterprise Advanced. Hosted (SaaS) Monitoring Tools\u00b6 These are monitoring tools provided as a hosted service, usually through a paid subscription. Name Notes MongoDB Cloud Manager MongoDB Cloud Manager is a cloud-based suite of services for managing MongoDB deployments. MongoDB Cloud Manager provides monitoring, backup, and automation functionality. For an on-premise solution, see also Ops Manager, available in MongoDB Enterprise Advanced. VividCortex VividCortex provides deep insights into MongoDB production database workload and query performance \u2013 in one-second resolution. Track latency, throughput, errors, and more to ensure scalability and exceptional performance of your application on MongoDB. Scout Several plugins, including MongoDB Monitoring, MongoDB Slow Queries, and MongoDB Replica Set Monitoring. Server Density Dashboard for MongoDB, MongoDB specific alerts, replication failover timeline and iPhone, iPad and Android mobile apps. Application Performance Management IBM has an Application Performance Management SaaS offering that includes monitor for MongoDB and other applications and middleware. New Relic New Relic offers full support for application performance management. In addition, New Relic Plugins and Insights enable you to view monitoring metrics from Cloud Manager in New Relic. Datadog Infrastructure monitoring to visualize the performance of your MongoDB deployments. SPM Performance Monitoring Monitoring, Anomaly Detection and Alerting SPM monitors all key MongoDB metrics together with infrastructure incl. Docker and other application metrics, e.g. Node.js, Java, NGINX, Apache, HAProxy or Elasticsearch. SPM provides correlation of metrics and logs. Process Logging\u00b6 During normal operation, mongod and mongos instances report a live account of all server activity and operations to either standard output or a log file. The following runtime settings control these options. quiet. Limits the amount of information written to the log or output. verbosity. Increases the amount of information written to the log or output. You can also modify the logging verbosity during runtime with the logLevel parameter or the db.setLogLevel() method in the shell. path. Enables logging to a file, rather than the standard output. You must specify the full path to the log file when adjusting this setting. logAppend. Adds information to a log file instead of overwriting the file. Note You can specify these configuration operations as the command line arguments to mongod or mongos For example: mongod -v --logpath /var/log/mongodb/server1.log --logappend Starts a mongod instance in verbose mode, appending data to the log file at /var/log/mongodb/server1.log/. The following database commands also affect logging: getLog. Displays recent messages from the mongod process log. logRotate. Rotates the log files for mongod processes only. See Rotate Log Files. Log Redaction\u00b6 New in version 3.4: Available in MongoDB Enterprise only A mongod running with security.redactClientLogData redacts messages associated with any given log event before logging, leaving only metadata, source files, or line numbers related to the event. security.redactClientLogData prevents potentially sensitive information from entering the system log at the cost of diagnostic detail. For example, the following operation inserts a document into a mongod running without log redaction. The mongod has systemLog.component.query.verbosity set to 0: db.clients.insertOne( { \"name\" : Joe, \"PII\" : \"Sensitive Information\" } ) This operation produces the following log event: 2016-09-23T13:51:43.572-0400 I COMMAND [conn1] command employeeData.directory appName: \"MongoDB Shell\" command: insert { insert: \"directory\", documents: [ { _id: ObjectId('57e56baf6a71e2b785153aec'), name: \"Joe\", PII: \"Sensitive Information\" } ], ... A mongod running with security.redactClientLogData performing the same insert operation produces the following log event: Note The exact redacted output may change leading up to the MongoDB 3.4 release. This output is based on the 3.3 development series build. 2016-09-23T13:51:43.572-0400 I COMMAND [conn1] ### Use redactClientLogData in conjunction with encryption to assist compliance with regulatory requirements. Diagnosing Performance Issues\u00b6 As you develop and operate applications with MongoDB, you may want to analyze the performance of the database as the application. MongoDB Performance discusses some of the operational factors that can influence performance. Replication and Monitoring\u00b6 Beyond the basic monitoring requirements for any MongoDB instance, for replica sets, administrators must monitor replication lag. \u201cReplication lag\u201d refers to the amount of time that it takes to copy (i.e. replicate) a write operation on the primary to a secondary. Some small delay period may be acceptable, but two significant problems emerge as replication lag grows: First, operations that occurred during the period of lag are not replicated to one or more secondaries. If you\u2019re using replication to ensure data persistence, exceptionally long delays may impact the integrity of your data set. Second, if the replication lag exceeds the length of the operation log (oplog) then MongoDB will have to perform an initial sync on the secondary, copying all data from the primary and rebuilding all indexes. This is uncommon under normal circumstances, but if you configure the oplog to be smaller than the default, the issue can arise. Note The size of the oplog is only configurable during the first run using the --oplogSize argument to the mongod command, or preferably, the oplogSizeMB setting in the MongoDB configuration file. If you do not specify this on the command line before running with the --replSet option, mongod will create a default sized oplog. By default, the oplog is 5 percent of total available disk space on 64-bit systems. For more information about changing the oplog size, see the Change the Size of the Oplog For causes of replication lag, see Replication Lag. Replication issues are most often the result of network connectivity issues between members, or the result of a primary that does not have the resources to support application and replication traffic. To check the status of a replica, use the replSetGetStatus or the following helper in the shell: rs.status() The replSetGetStatus reference provides a more in-depth overview view of this output. In general, watch the value of optimeDate, and pay particular attention to the time difference between the primary and the secondary members. Sharding and Monitoring\u00b6 In most cases, the components of sharded clusters benefit from the same monitoring and analysis as all other MongoDB instances. In addition, clusters require further monitoring to ensure that data is effectively distributed among nodes and that sharding operations are functioning appropriately. See also See the Sharding documentation for more information. Config Servers\u00b6 The config database maintains a map identifying which documents are on which shards. The cluster updates this map as chunks move between shards. When a configuration server becomes inaccessible, certain sharding operations become unavailable, such as moving chunks and starting mongos instances. However, clusters remain accessible from already-running mongos instances. Because inaccessible configuration servers can seriously impact the availability of a sharded cluster, you should monitor your configuration servers to ensure that the cluster remains well balanced and that mongos instances can restart. MongoDB Cloud Manager and Ops Manager monitor config servers and can create notifications if a config server becomes inaccessible. See the MongoDB Cloud Manager documentation and Ops Manager documentation for more information. Balancing and Chunk Distribution\u00b6 The most effective sharded cluster deployments evenly balance chunks among the shards. To facilitate this, MongoDB has a background balancer process that distributes data to ensure that chunks are always optimally distributed among the shards. Issue the db.printShardingStatus() or sh.status() command to the mongos by way of the mongo shell. This returns an overview of the entire cluster including the database name, and a list of the chunks. Stale Locks\u00b6 To check the lock status of the database, connect to a mongos instance using the mongo shell. Issue the following command sequence to switch to the config database and display all outstanding locks on the shard database: use config db.locks.find() The balancing process takes a special \u201cbalancer\u201d lock that prevents other balancing activity from transpiring. In the config database, use the following command to view the \u201cbalancer\u201d lock. db.locks.find( { _id : \"balancer\" } ) Changed in version 3.4: Starting in 3.4, the primary of the CSRS config server holds the \u201cbalancer\u201d lock, using a process id named \u201cConfigServer\u201d. This lock is never released. To determine if the balancer is running, see Check if Balancer is Running. Monitor MongoDB With SNMP on Linux Monitor MongoDB Windows with SNMP Troubleshoot SNMP Additional Resources\u00b6 MongoDB Production Readiness Consulting Package \u2190 Recover a Standalone after an Unexpected Shutdown Monitor MongoDB With SNMP on Linux \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/production-checklist-development.html",
      "title": "Development Checklist \u2014 MongoDB Manual 3.4",
      "text": "Administration > Development Checklist Development Checklist\u00b6 On this page Data Durability Schema Design Replication Sharding Drivers The following checklist, along with the Operations Checklist, provides recommendations to help you avoid issues in your production MongoDB deployment. Data Durability\u00b6 Ensure that your replica set includes at least three data-bearing nodes with w:majority write concern. Three data-bearing nodes are required for replica-set wide data durability. Ensure that all instances use journaling. Schema Design\u00b6 Data in MongoDB has a dynamic schema. Collections do not enforce document structure. This facilitates iterative development and polymorphism. Nevertheless, collections often hold documents with highly homogeneous structures. See Data Modeling Concepts for more information. Determine the set of collections that you will need and the indexes required to support your queries. With the exception of the _id index, you must create all indexes explicitly: MongoDB does not automatically create any indexes other than _id. Ensure that your schema design supports your deployment type: if you planning to use sharded clusters for horizontal scaling, design your schema to include a strong shard key. The shard key affects read and write performance by determining how MongoDB partitions data. See: Impacts of Shard Keys on Cluster Operations for information about what qualities a shard key should possess. You cannot change the shard key once it is set. Ensure that your schema design does not rely on indexed arrays that grow in length without bound. Typically, best performance can be achieved when such indexed arrays have fewer than 1000 elements. Consider the document size limits when designing your schema. The BSON Document Size limit is 16MB per document. If you require larger documents, use GridFS. Replication\u00b6 Use an odd number of replica set members to ensure that elections proceed successfully. If you have an even number of members, use an arbiter to ensure an odd number of votes. Note For replica sets with an arbiter, replica set protocol version 1 (pv1) increases the likelihood of rollback of w:1 writes compared to replica set protocol version 0 (pv0). See Replica Set Protocol Versions. Ensure that your secondaries remain up-to-date by using monitoring tools and by specifying appropriate write concern. Do not use secondary reads to scale overall read throughput. See: Can I use more replica nodes to scale for an overview of read scaling. For information about secondary reads, see: Read Preference. Sharding\u00b6 Ensure that your shard key distributes the load evenly on your shards. See: Shard Keys for more information. Use targeted operations for workloads that need to scale with the number of shards. Always read from primary nodes for non-targeted queries that may be sensitive to stale or orphaned data. Pre-split and manually balance chunks when inserting large data sets into a new non-hashed sharded collection. Pre-splitting and manually balancing enables the insert load to be distributed among the shards, increasing performance for the initial load. Drivers\u00b6 Make use of connection pooling. Most MongoDB drivers support connection pooling. Adjust the connection pool size to suit your use case, beginning at 110-115% of the typical number of concurrent database requests. Ensure that your applications handle transient write and read errors during replica set elections. Ensure that your applications handle failed requests and retry them if applicable. Drivers do not automatically retry failed requests. Use exponential backoff logic for database request retries. Use cursor.maxTimeMS() for reads and wtimeout for writes if you need to cap execution time for database operations. \u2190 Operations Checklist MongoDB Performance \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/production-checklist-operations.html",
      "title": "Operations Checklist \u2014 MongoDB Manual 3.4",
      "text": "Administration > Operations Checklist Operations Checklist\u00b6 On this page Filesystem Replication Sharding Journaling: MMAPv1 Storage Engine Hardware Deployments to Cloud Hardware Operating System Configuration Backups Monitoring Load Balancing The following checklist, along with the Development Checklist list, provides recommendations to help you avoid issues in your production MongoDB deployment. Filesystem\u00b6 Align your disk partitions with your RAID configuration. Avoid using NFS drives for your dbPath. Using NFS drives can result in degraded and unstable performance. See: Remote Filesystems for more information. VMWare users should use VMWare virtual drives over NFS. Linux/Unix: format your drives into XFS or EXT4. If possible, use XFS as it generally performs better with MongoDB. With the WiredTiger storage engine, use of XFS is strongly recommended to avoid performance issues found when using EXT4 with WiredTiger. If using RAID, you may need to configure XFS with your RAID geometry. Windows: use the NTFS file system. Do not use any FAT file system (i.e. FAT 16/32/exFAT). Replication\u00b6 Verify that all non-hidden replica set members are identically provisioned in terms of their RAM, CPU, disk, network setup, etc. Configure the oplog size to suit your use case: The replication oplog window should cover normal maintenance and downtime windows to avoid the need for a full resync. The replication oplog window should cover the time needed to restore a replica set member from the last backup. Changed in version 3.4: The replication oplog window no longer needs to cover the time needed to restore a replica set member via initial sync as the oplog records are pulled during the data copy. However, the member being restored must have enough disk space in the local database to temporarily store these oplog records for the duration of this data copy stage. With earlier versions of MongoDB, replication oplog window should cover the time needed to restore a replica set member by initial sync. Ensure that your replica set includes at least three data-bearing nodes that run with journaling and that you issue writes with w:\"majority\" write concern for availability and durability. Use hostnames when configuring replica set members, rather than IP addresses. Ensure full bidirectional network connectivity between all mongod instances. Ensure that each host can resolve itself. Ensure that your replica set contains an odd number of voting members. Ensure that mongod instances have 0 or 1 votes. For high availability, deploy your replica set into a minimum of three data centers. Sharding\u00b6 Place your config servers on dedicated hardware for optimal performance in large clusters. Ensure that the hardware has enough RAM to hold the data files entirely in memory and that it has dedicated storage. Use NTP to synchronize the clocks on all components of your sharded cluster. Ensure full bidirectional network connectivity between mongod, mongos and config servers. Use CNAMEs to identify your config servers to the cluster so that you can rename and renumber your config servers without downtime. Journaling: MMAPv1 Storage Engine\u00b6 Ensure that all instances use journaling. Place the journal on its own low-latency disk for write-intensive workloads. Note that this will affect snapshot-style backups as the files constituting the state of the database will reside on separate volumes. Hardware\u00b6 Use RAID10 and SSD drives for optimal performance. SAN and Virtualization: Ensure that each mongod has provisioned IOPS for its dbPath, or has its own physical drive or LUN. Avoid dynamic memory features, such as memory ballooning, when running in virtual environments. Avoid placing all replica set members on the same SAN, as the SAN can be a single point of failure. Deployments to Cloud Hardware\u00b6 Windows Azure: Adjust the TCP keepalive (tcp_keepalive_time) to 100-120. The default TTL for TCP connections on Windows Azure load balancers is too slow for MongoDB\u2019s connection pooling behavior. Use MongoDB version 2.6.4 or later on systems with high-latency storage, such as Windows Azure, as these versions include performance improvements for those systems. See: Azure Deployment Recommendations for more information. Operating System Configuration\u00b6 Linux\u00b6 Turn off transparent hugepages and defrag. See Transparent Huge Pages Settings for more information. Adjust the readahead settings on the devices storing your database files to suit your use case. For the MMAPv1 storage engine, if your working set is bigger that the available RAM, and the document access pattern is random, consider lowering the readahead to 32 or 16. Evaluate different settings to find an optimal value that maximizes the resident memory and lowers the number of page faults. For the WiredTiger storage engine, set readahead to 0 regardless of storage media type (spinning, SSD, etc.). In general, use the recommended readahead setting unless testing shows a measurable, repeatable, and reliable benefit in a higher readahead value. MongoDB Professional Support can provide advice and guidance on non-zero readahead configurations. Disable the tuned tool if you are running RHEL 7 / CentOS 7 in a virtual environment. When RHEL 7 / CentOS 7 run in a virtual environment, the tuned tool automatically invokes a performance profile derived from performance throughput, which automatically sets the readahead settings to 4MB. This can negatively impact performance. Use the noop or deadline disk schedulers for SSD drives. Use the noop disk scheduler for virtualized drives in guest VMs. Disable NUMA or set vm.zone_reclaim_mode to 0 and run mongod instances with node interleaving. See: MongoDB and NUMA Hardware for more information. Adjust the ulimit values on your hardware to suit your use case. If multiple mongod or mongos instances are running under the same user, scale the ulimit values accordingly. See: UNIX ulimit Settings for more information. Use noatime for the dbPath mount point. Configure sufficient file handles (fs.file-max), kernel pid limit (kernel.pid_max), and maximum threads per process (kernel.threads-max) for your deployment. For large systems, the following values provide a good starting point: fs.file-max value of 98000, kernel.pid_max value of 64000, and kernel.threads-max value of 64000 Ensure that your system has swap space configured. Refer to your operating system\u2019s documentation for details on appropriate sizing. Ensure that the system default TCP keepalive is set correctly. A value of 300 often provides better performance for replica sets and sharded clusters. See: Does TCP keepalive time affect MongoDB Deployments? in the Frequently Asked Questions for more information. Windows\u00b6 Consider disabling NTFS \u201clast access time\u201d updates. This is analogous to disabling atime on Unix-like systems. Backups\u00b6 Schedule periodic tests of your back up and restore process to have time estimates on hand, and to verify its functionality. Monitoring\u00b6 Use MongoDB Cloud Manager or Ops Manager, an on-premise solution available in MongoDB Enterprise Advanced or another monitoring system to monitor key database metrics and set up alerts for them. Include alerts for the following metrics: lock percent (for the MMAPv1 storage engine) replication lag replication oplog window assertions queues page faults Monitor hardware statistics for your servers. In particular, pay attention to the disk use, CPU, and available disk space. In the absence of disk space monitoring, or as a precaution: Create a dummy 4 GB file on the storage.dbPath drive to ensure available space if the disk becomes full. A combination of cron+df can alert when disk space hits a high-water mark, if no other monitoring tool is available. Load Balancing\u00b6 Configure load balancers to enable \u201csticky sessions\u201d or \u201cclient affinity\u201d, with a sufficient timeout for existing connections. Avoid placing load balancers between MongoDB cluster or replica set components. \u2190 Production Notes Development Checklist \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/production-notes.html",
      "title": "Production Notes \u2014 MongoDB Manual 3.4",
      "text": "Administration > Production Notes Production Notes\u00b6 On this page MongoDB Binaries MongoDB dbPath Concurrency Data Consistency Networking Hardware Considerations Architecture Compression Platform Specific Considerations Performance Monitoring Backups Additional Resources This page details system configurations that affect MongoDB, especially when running in production. Note MongoDB Atlas is a cloud-hosted database-as-a-service. MongoDB Cloud Manager, a hosted service, and Ops Manager, an on-premise solution, provide monitoring, backup, and automation of MongoDB instances. For documentation, see Atlas documentation, the MongoDB Cloud Manager documentation and Ops Manager documentation MongoDB Binaries\u00b6 Supported Platforms\u00b6 For running in production, refer to the Recommended Platforms for operating system recommendations. Changed in version 3.2: MongoDB can now use the WiredTiger storage engine on all supported platforms. x86_64\u00b6 Platform 3.4 Community & Enterprise 3.2 Community & Enterprise 3.0 Community & Enterprise Amazon Linux 2013.03 and later \u2713 \u2713 \u2713 Debian 7 \u2713 \u2713 \u2713 Debian 8 \u2713 \u2713 RHEL/CentOS 6.2 and later \u2713 \u2713 \u2713 RHEL/CentOS 7.0 and later \u2713 \u2713 \u2713 SLES 11 \u2713 \u2713 \u2713 SLES 12 \u2713 Solaris 11 64-bit Community only Community only Community only Ubuntu 12.04 \u2713 \u2713 \u2713 Ubuntu 14.04 \u2713 \u2713 \u2713 Ubuntu 16.04 \u2713 \u2713 Windows Server 2008R2 and later \u2713 \u2713 \u2713 Windows Vista and later \u2713 \u2713 \u2713 OS X 10.7 and later \u2713 \u2713 ARM64\u00b6 Platform 3.4 Community & Enterprise Ubuntu 16.04 \u2713 PPC64LE (MongoDB Enterprise Edition)\u00b6 Platform 3.4 Enterprise RHEL/CentOS 7.1 \u2713 Ubuntu 16.04 \u2713 s390x (MongoDB Enterprise Edition)\u00b6 Platform 3.4 Enterprise RHEL/CentOS 7.2 \u2713 SLES 11 \u2713 SLES 12 \u2713 Ubuntu 16.04 \u2713 Recommended Platforms\u00b6 While MongoDB supports a variety of platforms, the following operating systems are recommended for production use: Amazon Linux Debian 7.1 RHEL / CentOS 6.2+ SLES 11+ Ubuntu LTS 12.04 Ubuntu LTS 14.04 Windows Server 2012 & 2012 R2 See also Platform Specific Considerations Use the Latest Stable Packages\u00b6 Be sure you have the latest stable release. All MongoDB releases are available on the Downloads page. The Downloads page is a good place to verify the current stable release, even if you are installing via a package manager. The following summarizes the supported architecture for the latest version of MongoDB products: Product x86_64/amd64 s390x POWER8 (little endian) ARMv8-A MongoDB 3.4 \u2713 MongoDB Enterprise only MongoDB Enterprise only \u2713 BI Connector \u2713 \u2713 \u2713 Compass \u2713 Spark Connector \u2713 Ops Manager \u2713 Automation Agent \u2713 \u2713 Monitoring Agent \u2713 \u2713 Backup Agent \u2713 \u2713 MongoDB dbPath\u00b6 The files in the dbPath directory must correspond to the configured storage engine. mongod will not start if dbPath contains data files created by a storage engine other than the one specified by --storageEngine. Changed in version 3.2: As of MongoDB 3.2, MongoDB uses the WiredTiger storage engine by default. Changed in version 3.0: MongoDB includes support for two storage engines: MMAPv1, the storage engine available in previous versions of MongoDB, and WiredTiger. mongod must possess read and write permissions for the specified dbPath. Concurrency\u00b6 MMAPv1\u00b6 Changed in version 3.0: Beginning with MongoDB 3.0, MMAPv1 provides collection-level locking: All collections have a unique readers-writer lock that allows multiple clients to modify documents in different collections at the same time. For MongoDB versions 2.2 through 2.6 series, each database has a readers-writer lock that allows concurrent read access to a database, but gives exclusive access to a single write operation per database. See the Concurrency page for more information. In earlier versions of MongoDB, all write operations contended for a single readers-writer lock for the entire mongod instance. WiredTiger\u00b6 WiredTiger supports concurrent access by readers and writers to the documents in a collection. Clients can read documents while write operations are in progress, and multiple threads can modify different documents in a collection at the same time. See also Allocate Sufficient RAM and CPU provides information about how WiredTiger takes advantage of multiple CPU cores and how to improve operation throughput. Data Consistency\u00b6 Journaling\u00b6 MongoDB uses write ahead logging to an on-disk journal. Journaling guarantees that MongoDB can quickly recover write operations that were written to the journal but not written to data files in cases where mongod terminated due to a crash or other serious failure. Leave journaling enabled in order to ensure that mongod will be able to recover its data files and keep the data files in a valid state following a crash. See Journaling for more information. Read Concern\u00b6 New in version 3.2. If using \"majority\" or \"linearizable\" read concern for read operations, use { w: \"majority\" } write concern for write operations on the primary to ensure that a single thread can read its own writes. To use read concern level of \"majority\", you must start the mongod instances with the --enableMajorityReadConcern command line option (or the replication.enableMajorityReadConcern set to true if using a configuration file). replica sets must use WiredTiger storage engine and election protocol version 1. Write Concern\u00b6 Write concern describes the level of acknowledgement requested from MongoDB for write operations. The level of the write concerns affects how quickly the write operation returns. When write operations have a weak write concern, they return quickly. With stronger write concerns, clients must wait after sending a write operation until MongoDB confirms the write operation at the requested write concern level. With insufficient write concerns, write operations may appear to a client to have succeeded, but may not persist in some cases of server failure. See the Write Concern document for more information about choosing an appropriate write concern level for your deployment. Networking\u00b6 Use Trusted Networking Environments\u00b6 Always run MongoDB in a trusted environment, with network rules that prevent access from all unknown machines, systems, and networks. As with any sensitive system that is dependent on network access, your MongoDB deployment should only be accessible to specific systems that require access, such as application servers, monitoring services, and other MongoDB components. Important By default, authorization is not enabled, and mongod assumes a trusted environment. Enable authorization mode as needed. For more information on authentication mechanisms supported in MongoDB as well as authorization in MongoDB, see Authentication and Role-Based Access Control. For additional information and considerations on security, refer to the documents in the Security Section, specifically: Security Checklist MongoDB Configuration Hardening Hardening Network Infrastructure For Windows users, consider the Windows Server Technet Article on TCP Configuration when deploying MongoDB on Windows. Disable HTTP Interface\u00b6 MongoDB provides an HTTP interface to check the status of the server and, optionally, run queries. The HTTP interface is disabled by default. Do not enable the HTTP interface in production environments. Deprecated since version 3.2: HTTP interface for MongoDB See HTTP Status Interface. Manage Connection Pool Sizes\u00b6 Avoid overloading the connection resources of a mongod or mongos instance by adjusting the connection pool size to suit your use case. Start at 110-115% of the typical number of current database requests, and modify the connection pool size as needed. Refer to the Connection Pool Options for adjusting the connection pool size. The connPoolStats command returns information regarding the number of open connections to the current database for mongos and mongod instances in sharded clusters. See also Allocate Sufficient RAM and CPU. Hardware Considerations\u00b6 MongoDB is designed specifically with commodity hardware in mind and has few hardware requirements or limitations. MongoDB\u2019s core components run on little-endian hardware, primarily x86/x86_64 processors. Client libraries (i.e. drivers) can run on big or little endian systems. Allocate Sufficient RAM and CPU\u00b6 MMAPv1\u00b6 Due to its concurrency model, the MMAPv1 storage engine does not require many CPU cores. As such, increasing the number of cores can improve performance but does not provide significant return. At a minimum, ensure that your mongod or mongos has access to two real cores or one physical CPU. Increasing the amount of RAM accessible to MongoDB may help reduce the frequency of page faults. WiredTiger\u00b6 The WiredTiger storage engine is multithreaded and can take advantage of additional CPU cores. Specifically, the total number of active threads (i.e. concurrent operations) relative to the number of available CPUs can impact performance: Throughput increases as the number of concurrent active operations increases up to the number of CPUs. Throughput decreases as the number of concurrent active operations exceeds the number of CPUs by some threshold amount. The threshold depends on your application. You can determine the optimum number of concurrent active operations for your application by experimenting and measuring throughput. The output from mongostat provides statistics on the number of active reads/writes in the (ar|aw) column. With WiredTiger, MongoDB utilizes both the WiredTiger internal cache and the filesystem cache. Starting in 3.4, the WiredTiger internal cache, by default, will use the larger of either: 50% of RAM minus 1 GB, or 256 MB. Via the filesystem cache, MongoDB automatically uses all free memory that is not used by the WiredTiger cache or by other processes. Data in the filesystem cache is compressed. To adjust the size of the WiredTiger internal cache, see storage.wiredTiger.engineConfig.cacheSizeGB and --wiredTigerCacheSizeGB. Avoid increasing the WiredTiger internal cache size above its default value. Note The storage.wiredTiger.engineConfig.cacheSizeGB limits the size of the WiredTiger internal cache. The operating system will use the available free memory for filesystem cache, which allows the compressed MongoDB data files to stay in memory. In addition, the operating system will use any free RAM to buffer file system blocks and file system cache. To accommodate the additional consumers of RAM, you may have to decrease WiredTiger internal cache size. The default WiredTiger internal cache size value assumes that there is a single mongod instance per machine. If a single machine contains multiple MongoDB instances, then you should decrease the setting to accommodate the other mongod instances. If you run mongod in a container (e.g. lxc, cgroups, Docker, etc.) that does not have access to all of the RAM available in a system, you must set storage.wiredTiger.engineConfig.cacheSizeGB to a value less than the amount of RAM available in the container. The exact amount depends on the other processes running in the container. To view statistics on the cache and eviction rate, see the wiredTiger.cache field returned from the serverStatus command. Compression and Encryption\u00b6 When using encryption, CPUs equipped with AES-NI instruction-set extensions show significant performance advantages. If you are using MongoDB Enterprise with the Encrypted Storage Engine, choose a CPU that supports AES-NI for better performance. See also Concurrency Use Solid State Disks (SSDs)\u00b6 MongoDB has good results and a good price-performance ratio with SATA SSD (Solid State Disk). Use SSD if available and economical. Spinning disks can be performant, but SSDs\u2019 capacity for random I/O operations works well with the update model of MMAPv1. Commodity (SATA) spinning drives are often a good option, as the random I/O performance increase with more expensive spinning drives is not that dramatic (only on the order of 2x). Using SSDs or increasing RAM may be more effective in increasing I/O throughput. MongoDB and NUMA Hardware\u00b6 Running MongoDB on a system with Non-Uniform Access Memory (NUMA) can cause a number of operational problems, including slow performance for periods of time and high system process usage. When running MongoDB servers and clients on NUMA hardware, you should configure a memory interleave policy so that the host behaves in a non-NUMA fashion. MongoDB checks NUMA settings on start up when deployed on Linux (since version 2.0) and Windows (since version 2.6) machines. If the NUMA configuration may degrade performance, MongoDB prints a warning. See also The MySQL \u201cswap insanity\u201d problem and the effects of NUMA post, which describes the effects of NUMA on databases. The post introduces NUMA and its goals, and illustrates how these goals are not compatible with production databases. Although the blog post addresses the impact of NUMA for MySQL, the issues for MongoDB are similar. NUMA: An Overview. Configuring NUMA on Windows\u00b6 On Windows, memory interleaving must be enabled through the machine\u2019s BIOS. Consult your system documentation for details. Configuring NUMA on Linux\u00b6 When running MongoDB on Linux, you should disable zone reclaim in the sysctl settings using one of the following commands: echo 0 | sudo tee /proc/sys/vm/zone_reclaim_mode sudo sysctl -w vm.zone_reclaim_mode=0 Then, you should use numactl to start your mongod instances, including the config servers, mongos instances, and any clients. If you do not have the numactl command, refer to the documentation for your operating system to install the numactl package. The following operation demonstrates how to start a MongoDB instance using numactl: numactl --interleave=all <path> <options> The <path> is the path to the program you are starting and the <options> are any optional arguments to pass to the program. To fully disable NUMA behavior, you must perform both operations. For more information, see the Documentation for /proc/sys/vm/*. Disk and Storage Systems\u00b6 Swap\u00b6 Assign swap space for your systems. Allocating swap space can avoid issues with memory contention and can prevent the OOM Killer on Linux systems from killing mongod. For the MMAPv1 storage engine, the method mongod uses to map files to memory ensures that the operating system will never store MongoDB data in swap space. On Windows systems, using MMAPv1 requires extra swap space due to commitment limits. For details, see MongoDB on Windows. For the WiredTiger storage engine, given sufficient memory pressure, WiredTiger may store data in swap space. RAID\u00b6 Most MongoDB deployments should use disks backed by RAID-10. RAID-5 and RAID-6 do not typically provide sufficient performance to support a MongoDB deployment. Avoid RAID-0 with MongoDB deployments. While RAID-0 provides good write performance, it also provides limited availability and can lead to reduced performance on read operations, particularly when using Amazon\u2019s EBS volumes. Remote Filesystems\u00b6 With the MMAPv1 storage engine, the Network File System protocol (NFS) is not recommended as you may see performance problems when both the data files and the journal files are hosted on NFS. You may experience better performance if you place the journal on local or iscsi volumes. With the WiredTiger storage engine, WiredTiger objects may be stored on remote file systems if the remote file system conforms to ISO/IEC 9945-1:1996 (POSIX.1). Because remote file systems are often slower than local file systems, using a remote file system for storage may degrade performance. If you decide to use NFS, add the following NFS options to your /etc/fstab file: bg, nolock, and noatime. Separate Components onto Different Storage Devices\u00b6 For improved performance, consider separating your database\u2019s data, journal, and logs onto different storage devices, based on your application\u2019s access and write pattern. Mount the components as separate filesystems and use symbolic links to map each component\u2019s path to the device storing it. For the WiredTiger storage engine, you can also store the indexes on a different storage device. See storage.wiredTiger.engineConfig.directoryForIndexes. Note Using different storage devices will affect your ability to create snapshot-style backups of your data, since the files will be on different devices and volumes. Scheduling\u00b6 Scheduling for Virtual or Cloud Hosted Devices\u00b6 For local block devices attached to a virtual machine instance via the hypervisor or hosted by a cloud hosting provider, the guest operating system should use a noop scheduler for best performance. The noop scheduler allows the operating system to defer I/O scheduling to the underlying hypervisor. Scheduling for Physical Servers\u00b6 For physical servers, the operating system should use a deadline scheduler. The deadline scheduler caps maximum latency per request and maintains a good disk throughput that is best for disk-intensive database applications. Architecture\u00b6 Replica Sets\u00b6 See the Replica Set Architectures document for an overview of architectural considerations for replica set deployments. Sharded Clusters\u00b6 See Sharded Cluster Production Architecture for an overview of recommended sharded cluster architectures for production deployments. See also Development Checklist Compression\u00b6 WiredTiger can compress collection data using either snappy or zlib compression library. snappy provides a lower compression rate but has little performance cost, whereas zlib provides better compression rate but has a higher performance cost. By default, WiredTiger uses snappy compression library. To change the compression setting, see storage.wiredTiger.collectionConfig.blockCompressor. WiredTiger uses prefix compression on all indexes by default. Platform Specific Considerations\u00b6 Note MongoDB uses the GNU C Library (glibc) if available on a system. MongoDB requires version at least glibc-2.12-1.2.el6 to avoid a known bug with earlier versions. For best results use at least version 2.13. MongoDB on Linux\u00b6 Kernel and File Systems\u00b6 When running MongoDB in production on Linux, you should use Linux kernel version 2.6.36 or later, with either the XFS or EXT4 filesystem. If possible, use XFS as it generally performs better with MongoDB. With the WiredTiger storage engine, use of XFS is strongly recommended to avoid performance issues that may occur when using EXT4 with WiredTiger. With the MMAPv1 storage engine, MongoDB preallocates its database files before using them and often creates large files. As such, you should use the XFS or EXT4 file systems. If possible, use XFS as it generally performs better with MongoDB. In general, if you use the XFS file system, use at least version 2.6.25 of the Linux Kernel. If you use the EXT4 file system, use at least version 2.6.28 of the Linux Kernel. On Red Hat Enterprise Linux and CentOS, use at least version 2.6.18-194 of the Linux kernel. fsync() on Directories\u00b6 Important MongoDB requires a filesystem that supports fsync() on directories. For example, HGFS and Virtual Box\u2019s shared folders do not support this operation. Recommended Configuration\u00b6 For all MongoDB deployments: Use the Network Time Protocol (NTP) to synchronize time among your hosts. This is especially important in sharded clusters. For the WiredTiger and MMAPv1 storage engines, consider the following recommendations: Turn off atime for the storage volume containing the database files. Set the file descriptor limit, -n, and the user process limit (ulimit), -u, above 20,000, according to the suggestions in the ulimit reference. A low ulimit will affect MongoDB when under heavy use and can produce errors and lead to failed connections to MongoDB processes and loss of service. Disable Transparent Huge Pages. MongoDB performs better with normal (4096 bytes) virtual memory pages. See Transparent Huge Pages Settings. Disable NUMA in your BIOS. If that is not possible, see MongoDB on NUMA Hardware. Problems have been reported when using MongoDB with SELinux enabled. To avoid issues, disable SELinux when possible. If you are using SELinux on Red Hat, you must configure SELinux to be able to run MongoDB. See: Configure SELinux for MongoDB and Configure SELinux for MongoDB Enterprise for the required configuration. Note If you are using SELinux, any MongoDB operation that requires server-side JavaScript will result in segfault errors. Disable Server-Side Execution of JavaScript describes how to disable execution of server-side JavaScript. For the WiredTiger storage engine: Set the readahead setting to 0 regardless of storage media type (spinning, SSD, etc.). Setting a higher readahead benefits sequential I/O operations. However, since MongoDB disk access patterns are generally random, setting a higher readahead provides limited benefit or performance degradation. As such, for most workloads, a readahead of 0 provides optimal MongoDB performance. In general, set the readahead setting to 0 unless testing shows a measurable, repeatable, and reliable benefit in a higher readahead value. MongoDB Professional Support can provide advice and guidance on non-zero readahead configurations. For the MMAPv1 storage engine: Ensure that readahead settings for the block devices that store the database files are appropriate. For random access use patterns, set low readahead values. A readahead of 32 (16 kB) often works well. For a standard block device, you can run sudo blockdev --report to get the readahead settings and sudo blockdev --setra <value> <device> to change the readahead settings. Refer to your specific operating system manual for more information. MongoDB and TLS/SSL Libraries\u00b6 On Linux platforms, you may observe one of the following statements in the MongoDB log: <path to SSL libs>/libssl.so.<version>: no version information available (required by /usr/bin/mongod) <path to SSL libs>/libcrypto.so.<version>: no version information available (required by /usr/bin/mongod) These warnings indicate that the system\u2019s TLS/SSL libraries are different from the TLS/SSL libraries that the mongod was compiled against. Typically these messages do not require intervention; however, you can use the following operations to determine the symbol versions that mongod expects: objdump -T <path to mongod>/mongod | grep \" SSL_\" objdump -T <path to mongod>/mongod | grep \" CRYPTO_\" These operations will return output that resembles one the of the following lines: 0000000000000000 DF *UND* 0000000000000000 libssl.so.10 SSL_write 0000000000000000 DF *UND* 0000000000000000 OPENSSL_1.0.0 SSL_write The last two strings in this output are the symbol version and symbol name. Compare these values with the values returned by the following operations to detect symbol version mismatches: objdump -T <path to TLS/SSL libs>/libssl.so.1* objdump -T <path to TLS/SSL libs>/libcrypto.so.1* This procedure is neither exact nor exhaustive: many symbols used by mongod from the libcrypto library do not begin with CRYPTO_. MongoDB on Windows\u00b6 MongoDB 3.0 Using WiredTiger\u00b6 For MongoDB instances using the WiredTiger storage engine, performance on Windows is comparable to performance on Linux. MongoDB Using MMAPv1\u00b6 Install Hotfix for MongoDB 2.6.6 and Later\u00b6 Microsoft has released a hotfix for Windows 7 and Windows Server 2008 R2, KB2731284, that repairs a bug in these operating systems\u2019 use of memory-mapped files that adversely affects the performance of MongoDB using the MMAPv1 storage engine. Install this hotfix to obtain significant performance improvements on MongoDB 2.6.6 and later releases in the 2.6 series, which use MMAPv1 exclusively, and on 3.0 and later when using MMAPv1 as the storage engine. Configure Windows Page File For MMAPv1\u00b6 Configure the page file such that the minimum and maximum page file size are equal and at least 32 GB. Use a multiple of this size if, during peak usage, you expect concurrent writes to many databases or collections. However, the page file size does not need to exceed the maximum size of the database. A large page file is needed as Windows requires enough space to accommodate all regions of memory mapped files made writable during peak usage, regardless of whether writes actually occur. The page file is not used for database storage and will not receive writes during normal MongoDB operation. As such, the page file will not affect performance, but it must exist and be large enough to accommodate Windows\u2019 commitment rules during peak database use. Note Dynamic page file sizing is too slow to accommodate the rapidly fluctuating commit charge of an active MongoDB deployment. This can result in transient overcommitment situations that may lead to abrupt server shutdown with a VirtualProtect error 1455. MongoDB on Virtual Environments\u00b6 This section describes considerations when running MongoDB in some of the more common virtual environments. For all platforms, consider Scheduling. EC2\u00b6 MongoDB is compatible with EC2. MongoDB Cloud Manager provides integration with Amazon Web Services (AWS) and lets you deploy new EC2 instances directly from MongoDB Cloud Manager. See Configure AWS Integration for more details. Azure\u00b6 Use Premium Storage. Microsoft Azure offers two general types of storage: Standard storage, and Premium storage. MongoDB on Azure has better performance when using Premium storage than it does with Standard storage. For all MMAPv1 MongoDB deployments using Azure, you must mount the volume that hosts the mongod instance\u2019s dbPath with the Host Cache Preference READ/WRITE. This applies to all Azure deployments running MMAPv1, using any guest operating system. If your volumes have inappropriate cache settings, MongoDB may eventually shut down with the following error: [DataFileSync] FlushViewOfFile for <data file> failed with error 1 ... [DataFileSync] Fatal Assertion 16387 These shut downs do not produce data loss when storage.journal.enabled is set to true. You can safely restart mongod at any time following this event. The performance characteristics of MongoDB may change with READ/WRITE caching enabled. The TCP keepalive on the Azure load balancer is 240 seconds by default, which can cause it to silently drop connections if the TCP keepalive on your Azure systems is greater than this value. You should set tcp_keepalive_time to 120 to ameliorate this problem. On Linux systems: To view the keep alive setting, you can use one of the following commands: sysctl net.ipv4.tcp_keepalive_time Or: cat /proc/sys/net/ipv4/tcp_keepalive_time The value is measured in seconds. To change the tcp_keepalive_time value, you can use one of the following command: sudo sysctl -w net.ipv4.tcp_keepalive_time=<value> Or: echo <value> | sudo tee /proc/sys/net/ipv4/tcp_keepalive_time These operations do not persist across system reboots. To persist the setting, add the following line to /etc/sysctl.conf: net.ipv4.tcp_keepalive_time = <value> On Linux, mongod and mongos processes limit the keepalive to a maximum of 300 seconds (5 minutes) on their own sockets by overriding keepalive values greater than 5 minutes. For Windows systems: To view the keep alive setting, issue the following command: reg query HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters /v KeepAliveTime The registry value is not present by default. The system default, used if the value is absent, is 7200000 milliseconds or 0x6ddd00 in hexadecimal. To change the KeepAliveTime value, use the following command in an Administrator Command Prompt, where <value> is expressed in hexadecimal (e.g. 120000 is 0x1d4c0): reg add HKLM\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters\\ /v KeepAliveTime /d <value> Windows users should consider the Windows Server Technet Article on KeepAliveTime for more information on setting keep alive for MongoDB deployments on Windows systems. VMWare\u00b6 MongoDB is compatible with VMWare. VMWare supports memory overcommitment, where you can assign more memory to your virtual machines than the physical machine has available. When memory is overcommitted, the hypervisor reallocates memory between the virtual machines. VMWare\u2019s balloon driver (vmmemctl) reclaims the pages that are considered least valuable. The balloon driver resides inside the guest operating system. When the balloon driver expands, it may induce the guest operating system to reclaim memory from guest applications, which can interfere with MongoDB\u2019s memory management and affect MongoDB\u2019s performance. You can disable the balloon driver and VMWare\u2019s memory overcommitment feature to mitigate these problems. However, disabling the balloon driver can cause the hypervisor to use its swap, as there is no other available mechanism to perform the memory reclamation. Accessing data in swap is much slower than accessing data in memory, which can in turn affect performance. Instead of disabling the balloon driver and memory overcommitment features, map and reserve the full amount of memory for the virtual machine running MongoDB. This ensures that the balloon will not be inflated in the local operating system if there is memory pressure in the hypervisor due to an overcommitted configuration. When using MongoDB with VMWare, ensure that the CPU reservation does not exceed more than 2 virtual CPUs per physical core. Disable VMWare\u2019s Migration with vMotion (\u201clive migration\u201d). The live migration of a virtual machine can cause performance problems and affect replica set and sharded cluster high availability mechanisms. It is possible to clone a virtual machine running MongoDB. You might use this function to spin up a new virtual host to add as a member of a replica set. If you clone a VM with journaling enabled, the clone snapshot will be valid. If not using journaling, first stop mongod, then clone the VM, and finally, restart mongod. KVM\u00b6 MongoDB is compatible with KVM. KVM supports memory overcommitment, where you can assign more memory to your virtual machines than the physical machine has available. When memory is overcommitted, the hypervisor reallocates memory between the virtual machines. KVM\u2019s balloon driver reclaims the pages that are considered least valuable. The balloon driver resides inside the guest operating system. When the balloon driver expands, it may induce the guest operating system to reclaim memory from guest applications, which can interfere with MongoDB\u2019s memory management and affect MongoDB\u2019s performance. You can disable the balloon driver and KVM\u2019s memory overcommitment feature to mitigate these problems. However, disabling the balloon driver can cause the hypervisor to use its swap, as there is no other available mechanism to perform the memory reclamation. Accessing data in swap is much slower than accessing data in memory, which can in turn affect performance. Instead of disabling the balloon driver and memory overcommitment features, map and reserve the full amount of memory for the virtual machine running MongoDB. This ensures that the balloon will not be inflated in the local operating system if there is memory pressure in the hypervisor due to an overcommitted configuration. When using MongoDB with KVM, ensure that the CPU reservation does not exceed more than 2 virtual CPUs per physical core. Performance Monitoring\u00b6 iostat\u00b6 On Linux, use the iostat command to check if disk I/O is a bottleneck for your database. Specify a number of seconds when running iostat to avoid displaying stats covering the time since server boot. For example, the following command will display extended statistics and the time for each displayed report, with traffic in MB/s, at one second intervals: iostat -xmt 1 Key fields from iostat: %util: this is the most useful field for a quick check, it indicates what percent of the time the device/drive is in use. avgrq-sz: average request size. Smaller number for this value reflect more random IO operations. bwm-ng\u00b6 bwm-ng is a command-line tool for monitoring network use. If you suspect a network-based bottleneck, you may use bwm-ng to begin your diagnostic process. Backups\u00b6 To make backups of your MongoDB database, please refer to MongoDB Backup Methods Overview. Additional Resources\u00b6 Blog Post: Capacity Planning and Hardware Provisioning for MongoDB In Ten Minutes Whitepaper: MongoDB Multi-Data Center Deployments Whitepaper: Security Architecture Whitepaper: MongoDB Architecture Guide Presentation: MongoDB Administration 101 MongoDB Production Readiness Consulting Package \u2190 Administration Operations Checklist \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/replica-set-deployment.html",
      "title": "Replica Set Deployment Tutorials \u2014 MongoDB Manual 3.4",
      "text": "Replication > Replica Set Tutorials > Replica Set Deployment Tutorials Replica Set Deployment Tutorials\u00b6 The following tutorials provide information in deploying replica sets. Deploy a Replica Set Configure a three-member replica set for production systems. Deploy a Replica Set for Testing and Development Configure a three-member replica set for either development or testing systems. Deploy a Geographically Redundant Replica Set Create a geographically redundant replica set to protect against location-centered availability limitations (e.g. network and power interruptions). Add an Arbiter to Replica Set Add an arbiter give a replica set an odd number of voting members to prevent election ties. Convert a Standalone to a Replica Set Convert an existing standalone mongod instance into a three-member replica set. Add Members to a Replica Set Add a new member to an existing replica set. Remove Members from Replica Set Remove a member from a replica set. Replace a Replica Set Member Update the replica set configuration when the hostname of a member\u2019s corresponding mongod instance has changed. Deploy a Replica Set Deploy a Replica Set for Testing and Development Deploy a Geographically Redundant Replica Set Add an Arbiter to Replica Set Convert a Standalone to a Replica Set Add Members to a Replica Set Remove Members from Replica Set Replace a Replica Set Member \u2190 Replica Set Tutorials Deploy a Replica Set \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/replica-set-maintenance.html",
      "title": "Replica Set Maintenance Tutorials \u2014 MongoDB Manual 3.4",
      "text": "Replication > Replica Set Tutorials > Replica Set Maintenance Tutorials Replica Set Maintenance Tutorials\u00b6 The following tutorials provide information in maintaining existing replica sets. Change the Size of the Oplog Increase the size of the oplog which logs operations. In most cases, the default oplog size is sufficient. Perform Maintenance on Replica Set Members Perform maintenance on a member of a replica set while minimizing downtime. Force a Member to Become Primary Force a replica set member to become primary. Resync a Member of a Replica Set Sync the data on a member. Either perform initial sync on a new member or resync the data on an existing member that has fallen too far behind to catch up by way of normal replication. Configure Replica Set Tag Sets Assign tags to replica set members for use in targeting read and write operations to specific members. Reconfigure a Replica Set with Unavailable Members Reconfigure a replica set when a majority of replica set members are down or unreachable. Manage Chained Replication Disable or enable chained replication. Chained replication occurs when a secondary replicates from another secondary instead of the primary. Change Hostnames in a Replica Set Update the replica set configuration to reflect changes in members\u2019 hostnames. Configure a Secondary\u2019s Sync Target Specify the member that a secondary member synchronizes from. Change the Size of the Oplog Perform Maintenance on Replica Set Members Force a Member to Become Primary Resync a Member of a Replica Set Configure Replica Set Tag Sets Reconfigure a Replica Set with Unavailable Members Manage Chained Replication Change Hostnames in a Replica Set Configure a Secondary\u2019s Sync Target \u2190 Convert a Secondary to an Arbiter Change the Size of the Oplog \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/replica-set-member-configuration.html",
      "title": "Member Configuration Tutorials \u2014 MongoDB Manual 3.4",
      "text": "Replication > Replica Set Tutorials > Member Configuration Tutorials Member Configuration Tutorials\u00b6 The following tutorials provide information in configuring replica set members to support specific operations, such as to provide dedicated backups, to support reporting, or to act as a cold standby. Warning Avoid reconfiguring replica sets that contain members of different MongoDB versions as validation rules may differ across MongoDB versions. Adjust Priority for Replica Set Member Change the precedence given to a replica set members in an election for primary. Prevent Secondary from Becoming Primary Make a secondary member ineligible for election as primary. Configure a Hidden Replica Set Member Configure a secondary member to be invisible to applications in order to support significantly different usage, such as a dedicated backups. Configure a Delayed Replica Set Member Configure a secondary member to keep a delayed copy of the data set in order to provide a rolling backup. Configure Non-Voting Replica Set Member Create a secondary member that keeps a copy of the data set but does not vote in an election. Convert a Secondary to an Arbiter Convert a secondary to an arbiter. Adjust Priority for Replica Set Member Prevent Secondary from Becoming Primary Configure a Hidden Replica Set Member Configure a Delayed Replica Set Member Configure Non-Voting Replica Set Member Convert a Secondary to an Arbiter \u2190 Replace a Replica Set Member Adjust Priority for Replica Set Member \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/replica-sets.html",
      "title": "Replica Set Tutorials \u2014 MongoDB Manual 3.4",
      "text": "Replication > Replica Set Tutorials Replica Set Tutorials\u00b6 The administration of replica sets includes the initial deployment of the set, adding and removing members to a set, and configuring the operational parameters and properties of the set. Administrators generally need not intervene in failover or replication processes as MongoDB automates these functions. In the exceptional situations that require manual interventions, the tutorials in these sections describe processes such as resyncing a member. The tutorials in this section form the basis for all replica set administration. Replica Set Deployment Tutorials Instructions for deploying replica sets, as well as adding and removing members from an existing replica set. Deploy a Replica Set Configure a three-member replica set for production systems. Convert a Standalone to a Replica Set Convert an existing standalone mongod instance into a three-member replica set. Add Members to a Replica Set Add a new member to an existing replica set. Remove Members from Replica Set Remove a member from a replica set. Continue reading from Replica Set Deployment Tutorials for additional tutorials of related to setting up replica set deployments. Member Configuration Tutorials Tutorials that describe the process for configuring replica set members. Adjust Priority for Replica Set Member Change the precedence given to a replica set members in an election for primary. Prevent Secondary from Becoming Primary Make a secondary member ineligible for election as primary. Configure a Hidden Replica Set Member Configure a secondary member to be invisible to applications in order to support significantly different usage, such as a dedicated backups. Continue reading from Member Configuration Tutorials for more tutorials that describe replica set configuration. Replica Set Maintenance Tutorials Procedures and tasks for common operations on active replica set deployments. Change the Size of the Oplog Increase the size of the oplog which logs operations. In most cases, the default oplog size is sufficient. Resync a Member of a Replica Set Sync the data on a member. Either perform initial sync on a new member or resync the data on an existing member that has fallen too far behind to catch up by way of normal replication. Force a Member to Become Primary Force a replica set member to become primary. Change Hostnames in a Replica Set Update the replica set configuration to reflect changes in members\u2019 hostnames. Continue reading from Replica Set Maintenance Tutorials for descriptions of additional replica set maintenance procedures. Troubleshoot Replica Sets Describes common issues and operational challenges for replica sets. For additional diagnostic information, see FAQ: MongoDB Diagnostics. Replica Set Deployment Tutorials Deploy a Replica Set Deploy a Replica Set for Testing and Development Deploy a Geographically Redundant Replica Set Add an Arbiter to Replica Set Convert a Standalone to a Replica Set Add Members to a Replica Set Remove Members from Replica Set Replace a Replica Set Member Member Configuration Tutorials Adjust Priority for Replica Set Member Prevent Secondary from Becoming Primary Configure a Hidden Replica Set Member Configure a Delayed Replica Set Member Configure Non-Voting Replica Set Member Convert a Secondary to an Arbiter Replica Set Maintenance Tutorials Change the Size of the Oplog Perform Maintenance on Replica Set Members Force a Member to Become Primary Resync a Member of a Replica Set Configure Replica Set Tag Sets Reconfigure a Replica Set with Unavailable Members Manage Chained Replication Change Hostnames in a Replica Set Configure a Secondary\u2019s Sync Target Troubleshoot Replica Sets \u2190 Server Selection Algorithm Replica Set Deployment Tutorials \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/security-checklist.html",
      "title": "Security Checklist \u2014 MongoDB Manual 3.4",
      "text": "Security > Security Checklist Security Checklist\u00b6 On this page Enable Access Control and Enforce Authentication Configure Role-Based Access Control Encrypt Communication Encrypt and Protect Data Limit Network Exposure Audit System Activity Run MongoDB with a Dedicated User Run MongoDB with Secure Configuration Options Request a Security Technical Implementation Guide (where applicable) Consider Security Standards Compliance This documents provides a list of security measures that you should implement to protect your MongoDB installation. Enable Access Control and Enforce Authentication\u00b6 Enable access control and specify the authentication mechanism. You can use the default MongoDB authentication mechanism or an existing external framework. Authentication requires that all clients and servers provide valid credentials before they can connect to the system. In clustered deployments, enable authentication for each MongoDB server. See Authentication and Enable Auth. Configure Role-Based Access Control\u00b6 Create a user administrator first, then create additional users. Create a unique MongoDB user for each person and application that accesses the system. Create roles that define the exact access a set of users needs. Follow a principle of least privilege. Then create users and assign them only the roles they need to perform their operations. A user can be a person or a client application. See Role-Based Access Control and Manage Users and Roles. Encrypt Communication\u00b6 Configure MongoDB to use TLS/SSL for all incoming and outgoing connections. Use TLS/SSL to encrypt communication between mongod and mongos components of a MongoDB deployment as well as between all applications and MongoDB. See Configure mongod and mongos for TLS/SSL. Encrypt and Protect Data\u00b6 Starting with MongoDB Enterprise 3.2, the WiredTiger storage engine\u2019s native Encryption at Rest can be configured to encrypt data in the storage layer. If you are not using WiredTiger\u2019s encryption at rest, MongoDB data should be encrypted on each host using file-system, device, or physical encryption. Protect MongoDB data using file-system permissions. MongoDB data includes data files, configuration files, auditing logs, and key files. Limit Network Exposure\u00b6 Ensure that MongoDB runs in a trusted network environment and limit the interfaces on which MongoDB instances listen for incoming connections. Allow only trusted clients to access the network interfaces and ports on which MongoDB instances are available. See Security Hardening and the bindIp setting. Audit System Activity\u00b6 Track access and changes to database configurations and data. MongoDB Enterprise includes a system auditing facility that can record system events (e.g. user operations, connection events) on a MongoDB instance. These audit records permit forensic analysis and allow administrators to verify proper controls. See Auditing and Configure Auditing. Run MongoDB with a Dedicated User\u00b6 Run MongoDB processes with a dedicated operating system user account. Ensure that the account has permissions to access data but no unnecessary permissions. See Install MongoDB for more information on running MongoDB. Run MongoDB with Secure Configuration Options\u00b6 MongoDB supports the execution of JavaScript code for certain server-side operations: mapReduce, group, and $where. If you do not use these operations, disable server-side scripting by using the --noscripting option on the command line. Use only the MongoDB wire protocol on production deployments. Do not enable the following, all of which enable the web server interface: net.http.enabled, net.http.JSONPEnabled, and net.http.RESTInterfaceEnabled. Leave these disabled, unless required for backwards compatibility. Deprecated since version 3.2: HTTP interface for MongoDB Keep input validation enabled. MongoDB enables input validation by default through the wireObjectCheck setting. This ensures that all documents stored by the mongod instance are valid BSON. See Security Hardening for more information on hardening MongoDB configuration. Request a Security Technical Implementation Guide (where applicable)\u00b6 The Security Technical Implementation Guide (STIG) contains security guidelines for deployments within the United States Department of Defense. MongoDB Inc. provides its STIG, upon request, for situations where it is required. Please request a copy for more information. Consider Security Standards Compliance\u00b6 For applications requiring HIPAA or PCI-DSS compliance, please refer to the MongoDB Security Reference Architecture to learn more about how you can use the key security capabilities to build compliant application infrastructure. \u2190 Security Authentication \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/sharded-cluster-administration.html",
      "title": "Sharded Cluster Administration \u2014 MongoDB Manual 3.4",
      "text": "Sharding > Sharded Cluster Administration Sharded Cluster Administration\u00b6 Data Partitioning with Chunks Create Chunks in a Sharded Cluster Split Chunks in a Sharded Cluster Merge Chunks in a Sharded Cluster Modify Chunk Size in a Sharded Cluster Config Server Administration Replace a Config Server Upgrade Config Servers to Replica Set Upgrade Config Servers to Replica Set (Downtime) Balancer Administration Manage Sharded Cluster Balancer Migrate Chunks in a Sharded Cluster View Cluster Configuration Migrate a Sharded Cluster to Different Hardware Add Shards to a Cluster Remove Shards from an Existing Sharded Cluster Clear jumbo Flag Back Up Cluster Metadata Convert Sharded Cluster to Replica Set Convert a Replica Set to a Sharded Cluster Data Partitioning with Chunks MongoDB partitions data into chunks, which are distributed across the shards in the cluster Config Server Administration This section contains articles and tutorials related to sharded cluster config server administration Balancer Administration This section contains articles and tutorials related to sharded cluster balancer administration View Cluster Configuration View status information about the cluster\u2019s databases, shards, and chunks. Migrate a Sharded Cluster to Different Hardware Migrate a sharded cluster to a different hardware system, for example, when moving a pre-production environment to production. Add Shards to a Cluster Add a shard to add capacity to a sharded cluster. Remove Shards from an Existing Sharded Cluster Migrate a single shard\u2019s data and remove the shard. Clear jumbo Flag Manually clear jumbo flag from a chunk. Back Up Cluster Metadata Create a backup of a sharded cluster\u2019s metadata while keeping the cluster operational. Convert Sharded Cluster to Replica Set Convert a sharded cluster into a single replica set. Convert a Replica Set to a Sharded Cluster Convert a replica set to a sharded cluster in which each shard is its own replica set. \u2190 Deploy Sharded Cluster using Ranged Sharding Data Partitioning with Chunks \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/administration/sharded-cluster-config-servers.html",
      "title": "Sharded Cluster Config Server Administration \u2014 MongoDB Manual 3.4",
      "text": "Sharding > Sharded Cluster Administration > Sharded Cluster Config Server Administration Sharded Cluster Config Server Administration\u00b6 Replace a Config Server Upgrade Config Servers to Replica Set Upgrade Config Servers to Replica Set (Downtime) Replace a Config Server Replace a config server in a config server replica set. Upgrade Config Servers to Replica Set Perform a rolling upgrade a mirrored config server deployment to a replica set. MongoDB 3.2+ only. Upgrade Config Servers to Replica Set (Downtime) Upgrade a mirrored config server deployment to a replica set. MongoDB 3.2+ only. See also Backup and Restore Sharded Clusters \u2190 Modify Chunk Size in a Sharded Cluster Replace a Config Server \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/meta/aggregation-quick-reference.html",
      "title": "Aggregation Pipeline Quick Reference \u2014 MongoDB Manual 3.4",
      "text": "Aggregation > Aggregation Reference > Aggregation Pipeline Quick Reference Aggregation Pipeline Quick Reference\u00b6 On this page Stages Expressions Accumulators Note For details on specific operator, including syntax and examples, click on the specific operator to go to its reference page. Stages\u00b6 In the db.collection.aggregate method, pipeline stages appear in an array. Documents pass through the stages in sequence. All except the $out and $geoNear stages can appear multiple times in a pipeline. db.collection.aggregate( [ { <stage> }, ... ] ) Name Description $collStats Returns statistics regarding a collection or view. $project Reshapes each document in the stream, such as by adding new fields or removing existing fields. For each input document, outputs one document. $match Filters the document stream to allow only matching documents to pass unmodified into the next pipeline stage. $match uses standard MongoDB queries. For each input document, outputs either one document (a match) or zero documents (no match). $redact Reshapes each document in the stream by restricting the content for each document based on information stored in the documents themselves. Incorporates the functionality of $project and $match. Can be used to implement field level redaction. For each input document, outputs either one or zero documents. $limit Passes the first n documents unmodified to the pipeline where n is the specified limit. For each input document, outputs either one document (for the first n documents) or zero documents (after the first n documents). $skip Skips the first n documents where n is the specified skip number and passes the remaining documents unmodified to the pipeline. For each input document, outputs either zero documents (for the first n documents) or one document (if after the first n documents). $unwind Deconstructs an array field from the input documents to output a document for each element. Each output document replaces the array with an element value. For each input document, outputs n documents where n is the number of array elements and can be zero for an empty array. $group Groups input documents by a specified identifier expression and applies the accumulator expression(s), if specified, to each group. Consumes all input documents and outputs one document per each distinct group. The output documents only contain the identifier field and, if specified, accumulated fields. $sample Randomly selects the specified number of documents from its input. $sort Reorders the document stream by a specified sort key. Only the order changes; the documents remain unmodified. For each input document, outputs one document. $geoNear Returns an ordered stream of documents based on the proximity to a geospatial point. Incorporates the functionality of $match, $sort, and $limit for geospatial data. The output documents include an additional distance field and can include a location identifier field. $lookup Performs a left outer join to another collection in the same database to filter in documents from the \u201cjoined\u201d collection for processing. $out Writes the resulting documents of the aggregation pipeline to a collection. To use the $out stage, it must be the last stage in the pipeline. $indexStats Returns statistics regarding the use of each index for the collection. $facet Processes multiple aggregation pipelines within a single stage on the same set of input documents. Enables the creation of multi-faceted aggregations capable of characterizing data across multiple dimensions, or facets, in a single stage. $bucket Categorizes incoming documents into groups, called buckets, based on a specified expression and bucket boundaries. $bucketAuto Categorizes incoming documents into a specific number of groups, called buckets, based on a specified expression. Bucket boundaries are automatically determined in an attempt to evenly distribute the documents into the specified number of buckets. $sortByCount Groups incoming documents based on the value of a specified expression, then computes the count of documents in each distinct group. $addFields Adds new fields to documents. Outputs documents that contain all existing fields from the input documents and newly added fields. $replaceRoot Replaces a document with the specified embedded document. The operation replaces all existing fields in the input document, including the _id field. Specify a document embedded in the input document to promote the embedded document to the top level. $count Returns a count of the number of documents at this stage of the aggregation pipeline. $graphLookup Performs a recursive search on a collection. To each output document, adds a new array field that contains the traversal results of the recursive search for that document. Expressions\u00b6 Expressions can include field paths and system variables, literals, expression objects, and expression operators. Expressions can be nested. Field Path and System Variables\u00b6 Aggregation expressions use field path to access fields in the input documents. To specify a field path, use a string that prefixes with a dollar sign $ the field name or the dotted field name, if the field is in embedded document. For example, \"$user\" to specify the field path for the user field or \"$user.name\" to specify the field path to \"user.name\" field. \"$<field>\" is equivalent to \"$$CURRENT.<field>\" where the CURRENT is a system variable that defaults to the root of the current object in the most stages, unless stated otherwise in specific stages. CURRENT can be rebound. Along with the CURRENT system variable, other system variables are also available for use in expressions. To use user-defined variables, use $let and $map expressions. To access variables in expressions, use a string that prefixes the variable name with $$. Literals\u00b6 Literals can be of any type. However, MongoDB parses string literals that start with a dollar sign $ as a path to a field and numeric/boolean literals in expression objects as projection flags. To avoid parsing literals, use the $literal expression. Expression Objects\u00b6 Expression objects have the following form: { <field1>: <expression1>, ... } If the expressions are numeric or boolean literals, MongoDB treats the literals as projection flags (e.g. 1 or true to include the field), valid only in the $project stage. To avoid treating numeric or boolean literals as projection flags, use the $literal expression to wrap the numeric or boolean literals. Operator Expressions\u00b6 Operator expressions are similar to functions that take arguments. In general, these expressions take an array of arguments and have the following form: { <operator>: [ <argument1>, <argument2> ... ] } If operator accepts a single argument, you can omit the outer array designating the argument list: { <operator>: <argument> } To avoid parsing ambiguity if the argument is a literal array, you must wrap the literal array in a $literal expression or keep the outer array that designates the argument list. Boolean Expressions\u00b6 Boolean expressions evaluate their argument expressions as booleans and return a boolean as the result. In addition to the false boolean value, Boolean expression evaluates as false the following: null, 0, and undefined values. The Boolean expression evaluates all other values as true, including non-zero numeric values and arrays. Name Description $and Returns true only when all its expressions evaluate to true. Accepts any number of argument expressions. $or Returns true when any of its expressions evaluates to true. Accepts any number of argument expressions. $not Returns the boolean value that is the opposite of its argument expression. Accepts a single argument expression. Set Expressions\u00b6 Set expressions performs set operation on arrays, treating arrays as sets. Set expressions ignores the duplicate entries in each input array and the order of the elements. If the set operation returns a set, the operation filters out duplicates in the result to output an array that contains only unique entries. The order of the elements in the output array is unspecified. If a set contains a nested array element, the set expression does not descend into the nested array but evaluates the array at top-level. Name Description $setEquals Returns true if the input sets have the same distinct elements. Accepts two or more argument expressions. $setIntersection Returns a set with elements that appear in all of the input sets. Accepts any number of argument expressions. $setUnion Returns a set with elements that appear in any of the input sets. Accepts any number of argument expressions. $setDifference Returns a set with elements that appear in the first set but not in the second set; i.e. performs a relative complement of the second set relative to the first. Accepts exactly two argument expressions. $setIsSubset Returns true if all elements of the first set appear in the second set, including when the first set equals the second set; i.e. not a strict subset. Accepts exactly two argument expressions. $anyElementTrue Returns true if any elements of a set evaluate to true; otherwise, returns false. Accepts a single argument expression. $allElementsTrue Returns true if no element of a set evaluates to false, otherwise, returns false. Accepts a single argument expression. Comparison Expressions\u00b6 Comparison expressions return a boolean except for $cmp which returns a number. The comparison expressions take two argument expressions and compare both value and type, using the specified BSON comparison order for values of different types. Name Description $cmp Returns: 0 if the two values are equivalent, 1 if the first value is greater than the second, and -1 if the first value is less than the second. $eq Returns true if the values are equivalent. $gt Returns true if the first value is greater than the second. $gte Returns true if the first value is greater than or equal to the second. $lt Returns true if the first value is less than the second. $lte Returns true if the first value is less than or equal to the second. $ne Returns true if the values are not equivalent. Arithmetic Expressions\u00b6 Arithmetic expressions perform mathematic operations on numbers. Some arithmetic expressions can also support date arithmetic. Name Description $abs Returns the absolute value of a number. $add Adds numbers to return the sum, or adds numbers and a date to return a new date. If adding numbers and a date, treats the numbers as milliseconds. Accepts any number of argument expressions, but at most, one expression can resolve to a date. $ceil Returns the smallest integer greater than or equal to the specified number. $divide Returns the result of dividing the first number by the second. Accepts two argument expressions. $exp Raises e to the specified exponent. $floor Returns the largest integer less than or equal to the specified number. $ln Calculates the natural log of a number. $log Calculates the log of a number in the specified base. $log10 Calculates the log base 10 of a number. $mod Returns the remainder of the first number divided by the second. Accepts two argument expressions. $multiply Multiplies numbers to return the product. Accepts any number of argument expressions. $pow Raises a number to the specified exponent. $sqrt Calculates the square root. $subtract Returns the result of subtracting the second value from the first. If the two values are numbers, return the difference. If the two values are dates, return the difference in milliseconds. If the two values are a date and a number in milliseconds, return the resulting date. Accepts two argument expressions. If the two values are a date and a number, specify the date argument first as it is not meaningful to subtract a date from a number. $trunc Truncates a number to its integer. String Expressions\u00b6 String expressions, with the exception of $concat, only have a well-defined behavior for strings of ASCII characters. $concat behavior is well-defined regardless of the characters used. Name Description $concat Concatenates any number of strings. $indexOfBytes Searches a string for an occurence of a substring and returns the UTF-8 byte index of the first occurence. If the substring is not found, returns -1. $indexOfCP Searches a string for an occurence of a substring and returns the UTF-8 code point index of the first occurence. If the substring is not found, returns -1. $split Splits a string into substrings based on a delimiter. Returns an array of substrings. If the delimiter is not found within the string, returns an array containing the original string. $strLenBytes Returns the number of UTF-8 encoded bytes in a string. $strLenCP Returns the number of UTF-8 code points in a string. $strcasecmp Performs case-insensitive string comparison and returns: 0 if two strings are equivalent, 1 if the first string is greater than the second, and -1 if the first string is less than the second. $substr Deprecated. Use $substrBytes or $substrCP. $substrBytes Returns the substring of a string. Starts with the character at the specified UTF-8 byte index (zero-based) in the string and continues for the specified number of bytes. $substrCP Returns the substring of a string. Starts with the character at the specified UTF-8 code point (CP) index (zero-based) in the string and continues for the number of code points specified. $toLower Converts a string to lowercase. Accepts a single argument expression. $toUpper Converts a string to uppercase. Accepts a single argument expression. Text Search Expressions\u00b6 Name Description $meta Access text search metadata. Array Expressions\u00b6 Name Description $arrayElemAt Returns the element at the specified array index. $concatArrays Concatenates arrays to return the concatenated array. $filter Selects a subset of the array to return an array with only the elements that match the filter condition. $indexOfArray Searches an array for an occurence of a specified value and returns the array index of the first occurence. If the substring is not found, returns -1. $isArray Determines if the operand is an array. Returns a boolean. $range Outputs an array containing a sequence of integers according to user-defined inputs. $reverseArray Returns an array with the elements in reverse order. $reduce Applies an expression to each element in an array and combines them into a single value. $size Returns the number of elements in the array. Accepts a single expression as argument. $slice Returns a subset of an array. $zip Merge two lists together. $in Returns a boolean indicating whether a specified value is in an array. Variable Expressions\u00b6 Name Description $map Applies a subexpression to each element of an array and returns the array of resulting values in order. Accepts named parameters. $let Defines variables for use within the scope of a subexpression and returns the result of the subexpression. Accepts named parameters. Literal Expressions\u00b6 Name Description $literal Return a value without parsing. Use for values that the aggregation pipeline may interpret as an expression. For example, use a $literal expression to a string that starts with a $ to avoid parsing as a field path. Data Type Expressions\u00b6 Name Description $type Return the BSON data type of the field. Date Expressions\u00b6 Name Description $dayOfYear Returns the day of the year for a date as a number between 1 and 366 (leap year). $dayOfMonth Returns the day of the month for a date as a number between 1 and 31. $dayOfWeek Returns the day of the week for a date as a number between 1 (Sunday) and 7 (Saturday). $year Returns the year for a date as a number (e.g. 2014). $month Returns the month for a date as a number between 1 (January) and 12 (December). $week Returns the week number for a date as a number between 0 (the partial week that precedes the first Sunday of the year) and 53 (leap year). $hour Returns the hour for a date as a number between 0 and 23. $minute Returns the minute for a date as a number between 0 and 59. $second Returns the seconds for a date as a number between 0 and 60 (leap seconds). $millisecond Returns the milliseconds of a date as a number between 0 and 999. $dateToString Returns the date as a formatted string. $isoDayOfWeek Returns the weekday number in ISO 8601 format, ranging from 1 (for Monday) to 7 (for Sunday). $isoWeek Returns the week number in ISO 8601 format, ranging from 1 to 53. Week numbers start at 1 with the week (Monday through Sunday) that contains the year\u2019s first Thursday. $isoWeekYear Returns the year number in ISO 8601 format. The year starts with the Monday of week 1 (ISO 8601) and ends with the Sunday of the last week (ISO 8601). Conditional Expressions\u00b6 Name Description $cond A ternary operator that evaluates one expression, and depending on the result, returns the value of one of the other two expressions. Accepts either three expressions in an ordered list or three named parameters. $ifNull Returns either the non-null result of the first expression or the result of the second expression if the first expression results in a null result. Null result encompasses instances of undefined values or missing fields. Accepts two expressions as arguments. The result of the second expression can be null. $switch Evaluates a series of case expressions. When it finds an expression which evaluates to true, $switch executes a specified expression and breaks out of the control flow. Accumulators\u00b6 Changed in version 3.2: Some accumulators are now available in the $project stage. In previous versions of MongoDB , accumulators are available only for the $group stage. Accumulators, when used in the $group stage, maintain their state (e.g. totals, maximums, minimums, and related data) as documents progress through the pipeline. When used in the $group stage, accumulators take as input a single expression, evaluating the expression once for each input document, and maintain their stage for the group of documents that share the same group key. When used in the $project stage, the accumulators do not maintain their state. When used in the $project stage, accumulators take as input either a single argument or multiple arguments. Name Description $sum Returns a sum of numerical values. Ignores non-numeric values. Changed in version 3.2: Available in both $group and $project stages. $avg Returns an average of numerical values. Ignores non-numeric values. Changed in version 3.2: Available in both $group and $project stages. $first Returns a value from the first document for each group. Order is only defined if the documents are in a defined order. Available in $group stage only. $last Returns a value from the last document for each group. Order is only defined if the documents are in a defined order. Available in $group stage only. $max Returns the highest expression value for each group. Changed in version 3.2: Available in both $group and $project stages. $min Returns the lowest expression value for each group. Changed in version 3.2: Available in both $group and $project stages. $push Returns an array of expression values for each group. Available in $group stage only. $addToSet Returns an array of unique expression values for each group. Order of the array elements is undefined. Available in $group stage only. $stdDevPop Returns the population standard deviation of the input values. Changed in version 3.2: Available in both $group and $project stages. $stdDevSamp Returns the sample standard deviation of the input values. Changed in version 3.2: Available in both $group and $project stages. \u2190 Aggregation Reference Aggregation Commands \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/meta/build.html",
      "title": "MongoDB Documentation Build System \u2014 MongoDB Manual 3.4",
      "text": "MongoDB Documentation Build System\u00b6 This document contains more direct instructions for building the MongoDB documentation. Getting Started\u00b6 Install Dependencies\u00b6 The MongoDB Documentation project depends on the following tools: Python Git Inkscape (Image generation.) LaTeX/PDF LaTeX (typically texlive; for building PDFs) Giza OS X\u00b6 Install Sphinx, Docutils, and their dependencies with easy_install the following command: easy_install giza Feel free to use pip rather than easy_install to install python packages. To generate the images used in the documentation, download and install Inkscape. Optional To generate PDFs for the full production build, install a TeX distribution (for building the PDF.) If you do not have a LaTeX installation, use MacTeX. This is only required to build PDFs. Arch Linux\u00b6 Install packages from the system repositories with the following command: pacman -S inkscape python2-pip Then install the following Python packages: pip2 install giza Optional To generate PDFs for the full production build, install the following packages from the system repository: pacman -S texlive-bin texlive-core texlive-latexextra Debian/Ubuntu\u00b6 Install the required system packages with the following command: apt-get install inkscape python-pip Then install the following Python packages: pip install giza Optional To generate PDFs for the full production build, install the following packages from the system repository: apt-get install texlive-latex-recommended texlive-latex-recommended Setup and Configuration\u00b6 Clone the repository: git clone git://github.com/mongodb/docs.git Building the Documentation\u00b6 The MongoDB documentation build system is entirely accessible via make targets. For example, to build an HTML version of the documentation issue the following command: make html You can find the build output in build/<branch>/html, where <branch> is the name of the current branch. In addition to the html target, the build system provides the following targets: publish Builds and integrates all output for the production build. Build output is in build/public/<branch>/. When you run publish in the master, the build will generate some output in build/public/. push; stage Uploads the production build to the production or staging web servers. Depends on publish. Requires access production or staging environment. push-all; stage-all Uploads the entire content of build/public/ to the web servers. Depends on publish. Not used in common practice. push-with-delete; stage-with-delete Modifies the action of push and stage to remove remote file that don\u2019t exist in the local build. Use with caution. html; latex; dirhtml; epub; texinfo; man; json These are standard targets derived from the default Sphinx Makefile, with adjusted dependencies. Additionally, for all of these targets you can append -nitpick to increase Sphinx\u2019s verbosity, or -clean to remove all Sphinx build artifacts. latex performs several additional post-processing steps on .tex output generated by Sphinx. This target will also compile PDFs using pdflatex. html and man also generates a .tar.gz file of the build outputs for inclusion in the final releases. \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/meta/images-guide.html",
      "title": "Adding Images \u2014 MongoDB Manual 3.4",
      "text": "Adding Images\u00b6 Note This guide is advisory, and its suggestions do not necessarily apply to every situation. Without Giza (Recommended)\u00b6 Adding an SVG\u00b6 Whenever possible, you should publish diagrams in SVG form. This provides a crisp image at any screen resolution with a small file size. First install mut, Inkscape, and svgo. Place your SVG in source/images/. If you named your SVG foo.svg, then run the following: mut-images foo.svg This will generate foo.bakedsvg.svg. This baked SVG file contains no text: to prevent users from needing to download any fonts, mut-images transforms all text elements into paths. It then uses svgo to minify the resulting SVG file. Create a source/images/foo.rst file with contents such as the following: .. figure:: /images/foo.bakedsvg.svg :alt: An example image. :figwidth: 500px Check in and commit all three files. Adding a PNG\u00b6 Not all images start their life as an SVG. The process is less refined for adding these files, but in general keep the resolution under two times the display width. For example, if you want to display an image as 500px wide, the image itself should not be wider than 1000px. Note The MongoDB Documentation Project does not currently have a best practice for handling very large (>1080p) files or photographic content. It may make sense to use mozjpeg if you need lossy compression; imagemagick to resize images; and a Ninja file to put the pieces together. The default libpng encoder does not create optimal PNG files, so install zopflipng. To compress a PNG, use the following template: zopflipng -m <input.png> <output.png> This may take several minutes, as the -m option requests a brute-force search for optimal compression parameters. Place the output PNG in source/images/, and create a source/images/foo.rst file with contents such as the following: .. figure:: /images/foo.png :alt: An example image. :figwidth: 500px With Giza\u00b6 Some MongoDB documentation projects use Giza\u2019s image generation. This can be effective when you need images rendered at different sizes for different output formats. It has the following disadvantages: Giza only accepts SVGs: you must embed raster files inside of an SVG, Giza invokes inkscape for each input file, and Reliability problems. There was one instance where giza generated some images sans any text. Giza looks for the path listed in system.files.data.files within config/build_conf.yaml for a manifest containing image metadata. The image metadata is a YAML list of documents such as the following: name: opsmanager-large alt: \"A highly available deployment uses horizontal scaling of the application database and backup blockstore database, as well as multiple backup daemons.\" output: - type: print tag: 'print' dpi: 300 width: 2100 - type: web dpi: 72 width: 700 From this example, Giza will generate the following files in the build directory: /source/images/opsmanager-large.rst /source/images/opsmanager-large.png /source/images/opsmanager-large-print.png \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/meta/organization.html",
      "title": "MongoDB Manual Organization \u2014 MongoDB Manual 3.4",
      "text": "MongoDB Manual Organization\u00b6 This document provides an overview of the global organization of the documentation resource. Refer to the notes below if you are having trouble understanding the reasoning behind a file\u2019s current location, or if you want to add new documentation but aren\u2019t sure how to integrate it into the existing resource. If you have questions, don\u2019t hesitate to open a ticket in the Documentation Jira Project or contact the documentation team. Global Organization\u00b6 Indexes and Experience\u00b6 The documentation project has two \u201cindex files\u201d: /contents.txt and /index.txt. The \u201ccontents\u201d file provides the documentation\u2019s tree structure, which Sphinx uses to create the left-pane navigational structure, to power the \u201cNext\u201d and \u201cPrevious\u201d page functionality, and to provide all overarching outlines of the resource. The \u201cindex\u201d file is not included in the \u201ccontents\u201d file (and thus builds will produce a warning here) and is the page that users first land on when visiting the resource. Having separate \u201ccontents\u201d and \u201cindex\u201d files provides a bit more flexibility with the organization of the resource while also making it possible to customize the primary user experience. Topical Organization\u00b6 The placement of files in the repository depends on the type of documentation rather than the topic of the content. Like the difference between contents.txt and index.txt, by decoupling the organization of the files from the organization of the information the documentation can be more flexible and can more adequately address changes in the product and in users\u2019 needs. Files in the source/ directory represent the tip of a logical tree of documents, while directories are containers of types of content. The administration and applications directories, however, are legacy artifacts and with a few exceptions contain sub-navigation pages. With several exceptions in the reference/ directory, there is only one level of sub-directories in the source/ directory. Tools\u00b6 The organization of the site, like all Sphinx sites derives from the toctree structure. However, in order to annotate the table of contents and provide additional flexibility, the MongoDB documentation generates toctree structures using data from YAML files stored in the source/includes/ directory. These files start with ref-toc or toc and generate output in the source/includes/toc/ directory. Briefly this system has the following behavior: files that start with ref-toc refer to the documentation of API objects (i.e. commands, operators and methods), and the build system generates files that hold toctree directives as well as files that hold tables that list objects and a brief description. files that start with toc refer to all other documentation and the build system generates files that hold toctree directives as well as files that hold definition lists that contain links to the documents and short descriptions the content. file names that have spec following toc or ref-toc will generate aggregated tables or definition lists and allow ad-hoc combinations of documents for landing pages and quick reference guides. \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/meta/pdfs.html",
      "title": "PDF Removal \u2014 MongoDB Manual 3.4",
      "text": "PDF Removal\u00b6 The MongoDB Documentation Project no longer publishes documentation in the PDF format. Please use the EPUB Edition instead. \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/meta/practices.html",
      "title": "MongoDB Documentation Practices and Processes \u2014 MongoDB Manual 3.4",
      "text": "MongoDB Documentation Practices and Processes\u00b6 This document provides an overview of the practices and processes. Commits\u00b6 When relevant, include a Jira case identifier in a commit message. Reference documentation cases when applicable, but feel free to reference other cases from jira.mongodb.org. Err on the side of creating a larger number of discrete commits rather than bundling large set of changes into one commit. For the sake of consistency, remove trailing whitespaces in the source file. \u201cHard wrap\u201d files to between 72 and 80 characters per-line. Standards and Practices\u00b6 At least two people should vet all non-trivial changes to the documentation before publication. One of the reviewers should have significant technical experience with the material covered in the documentation. All development and editorial work should transpire on GitHub branches or forks that editors can then merge into the publication branches. Collaboration\u00b6 To propose a change to the documentation, do either of the following: Open a ticket in the documentation project proposing the change. Someone on the documentation team will make the change and be in contact with you so that you can review the change. Using GitHub, fork the mongodb/docs repository, commit your changes, and issue a pull request. Someone on the documentation team will review and incorporate your change into the documentation. Builds\u00b6 Building the documentation is useful because Sphinx and docutils can catch numerous errors in the format and syntax of the documentation. Additionally, having access to an example documentation as it will appear to the users is useful for providing more effective basis for the review process. Besides Sphinx, Pygments, and Python-Docutils, the documentation repository contains all requirements for building the documentation resource. Talk to someone on the documentation team if you are having problems running builds yourself. Publication\u00b6 The makefile for this repository contains targets that automate the publication process. Use make html to publish a test build of the documentation in the build/ directory of your repository. Use make publish to build the full contents of the manual from the current branch in the ../public-docs/ directory relative the docs repository. Other targets include: man - builds UNIX Manual pages for all Mongodb utilities. push - builds and deploys the contents of the ../public-docs/. pdfs - builds a PDF version of the manual (requires LaTeX dependencies.) Branches\u00b6 This section provides an overview of the git branches in the MongoDB documentation repository and their use. At the present time, future work transpires in the master, with the main publication being current. As the documentation stabilizes, the documentation team will begin to maintain branches of the documentation for specific MongoDB releases. Migration from Legacy Documentation\u00b6 The MongoDB.org Wiki contains a wealth of information. As the transition to the Manual (i.e. this project and resource) continues, it\u2019s critical that no information disappears or goes missing. The following process outlines how to migrate a wiki page to the manual: Read the relevant sections of the Manual, and see what the new documentation has to offer on a specific topic. In this process you should follow cross references and gain an understanding of both the underlying information and how the parts of the new content relates its constituent parts. Read the wiki page you wish to redirect, and take note of all of the factual assertions, examples presented by the wiki page. Test the factual assertions of the wiki page to the greatest extent possible. Ensure that example output is accurate. In the case of commands and reference material, make sure that documented options are accurate. Make corrections to the manual page or pages to reflect any missing pieces of information. The target of the redirect need not contain every piece of information on the wiki page, if the manual as a whole does, and relevant section(s) with the information from the wiki page are accessible from the target of the redirection. As necessary, get these changes reviewed by another writer and/or someone familiar with the area of the information in question. At this point, update the relevant Jira case with the target that you\u2019ve chosen for the redirect, and make the ticket unassigned. When someone has reviewed the changes and published those changes to Manual, you, or preferably someone else on the team, should make a final pass at both pages with fresh eyes and then make the redirect. Steps 1-5 should ensure that no information is lost in the migration, and that the final review in step 6 should be trivial to complete. Review Process\u00b6 Types of Review\u00b6 The content in the Manual undergoes many types of review, including the following: Initial Technical Review\u00b6 Review by an engineer familiar with MongoDB and the topic area of the documentation. This review focuses on technical content, and correctness of the procedures and facts presented, but can improve any aspect of the documentation that may still be lacking. When both the initial technical review and the content review are complete, the piece may be \u201cpublished.\u201d Content Review\u00b6 Textual review by another writer to ensure stylistic consistency with the rest of the manual. Depending on the content, this may precede or follow the initial technical review. When both the initial technical review and the content review are complete, the piece may be \u201cpublished.\u201d Consistency Review\u00b6 This occurs post-publication and is content focused. The goals of consistency reviews are to increase the internal consistency of the documentation as a whole. Insert relevant cross-references, update the style as needed, and provide background fact-checking. When possible, consistency reviews should be as systematic as possible and we should avoid encouraging stylistic and information drift by editing only small sections at a time. Subsequent Technical Review\u00b6 If the documentation needs to be updated following a change in functionality of the server or following the resolution of a user issue, changes may be significant enough to warrant additional technical review. These reviews follow the same form as the \u201cinitial technical review,\u201d but is often less involved and covers a smaller area. Review Methods\u00b6 If you\u2019re not a usual contributor to the documentation and would like to review something, you can submit reviews in any of the following methods: If you\u2019re reviewing an open pull request in GitHub, the best way to comment is on the \u201coverview diff,\u201d which you can find by clicking on the \u201cdiff\u201d button in the upper left portion of the screen. You can also use the following URL to reach this interface: https://github.com/mongodb/docs/pull/[pull-request-id]/files Replace [pull-request-id] with the identifier of the pull request. Make all comments inline, using GitHub\u2019s comment system. You may also provide comments directly on commits, or on the pull request itself but these commit-comments are archived in less coherent ways and generate less useful emails, while comments on the pull request lead to less specific changes to the document. Leave feedback on Jira cases in the DOCS project. These are better for more general changes that aren\u2019t necessarily tied to a specific line, or affect multiple files. Create a fork of the repository in your GitHub account, make any required changes and then create a pull request with your changes. If you insert lines that begin with any of the following annotations: .. TODO: TODO: .. TODO TODO followed by your comments, it will be easier for the original writer to locate your comments. The two dots .. format is a comment in reStructured Text, which will hide your comments from Sphinx and publication if you\u2019re worried about that. This format is often easier for reviewers with larger portions of content to review. \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/meta/style-guide.html",
      "title": "Style Guide and Documentation Conventions \u2014 MongoDB Manual 3.4",
      "text": "Style Guide and Documentation Conventions\u00b6 This document provides an overview of the style for the MongoDB documentation stored in this repository. The overarching goal of this style guide is to provide an accessible base style to ensure that our documentation is easy to read, simple to use, and straightforward to maintain. For information regarding the MongoDB Manual organization, see MongoDB Manual Organization. Document History\u00b6 2011-09-27: Document created with a (very) rough list of style guidelines, conventions, and questions. 2012-01-12: Document revised based on slight shifts in practice, and as part of an effort of making it easier for people outside of the documentation team to contribute to documentation. 2012-03-21: Merged in content from the Jargon, and cleaned up style in light of recent experiences. 2012-08-10: Addition to the \u201cReferencing\u201d section. 2013-02-07: Migrated this document to the manual. Added \u201cmap-reduce\u201d terminology convention. Other edits. 2013-11-15: Added new table of preferred terms. 2016-01-05: Standardizing on \u2018embedded document\u2019 Naming Conventions\u00b6 This section contains guidelines on naming files, sections, documents, and other document elements. File naming convention: For Sphinx, all files should have a .txt extension. Separate words in file names with hyphens (i.e. -.) For most documents, file names should have a terse one or two word name that describes the material covered in the document. Allow the path of the file within the document tree to add some of the required context/categorization. For example it\u2019s acceptable to have /core/sharding.rst and /administration/sharding.rst. For tutorials, the full title of the document should be in the file name. For example, /tutorial/replace-one-configuration-server-in-a-shard-cluster.rst Phrase headlines and titles so users can determine what questions the text will answer, and material that will be addressed, without needing them to read the content. This shortens the amount of time that people spend looking for answers, and improves search/scanning and possibly \u201cSEO.\u201d Prefer titles and headers in the form of \u201cUsing foo\u201d over \u201cHow to Foo.\u201d When using target references (i.e. :ref: references in documents), use names that include enough context to be intelligible through all documentation. For example, use \u201creplica-set-secondary-only-node\u201d as opposed to \u201csecondary-only-node\u201d. This makes the source more usable and easier to maintain. Style Guide\u00b6 This includes the typesetting and English grammatical conventions that all documents in the manual should use. The goal here is to choose good standards, that are clear, and have a stylistic minimalism that does not interfere with or distract from the content. A uniform style will improve user experience and minimize the effect of a multi-authored document. Spelling\u00b6 Use American spelling. Punctuation\u00b6 Use the Oxford comma. Oxford commas are the commas in a list of things (e.g. \u201csomething, something else, and another thing\u201d) before the conjunction (e.g. \u201cand\u201d or \u201cor.\u201d). Use a single space after terminal punctuation, such as periods. Place commas and periods inside quotation marks. Headings\u00b6 Use title case for headings and document titles. Title case capitalizes the first letter of the first, last, and all significant words. Verbs\u00b6 Verb tense and mood preferences, with examples: Avoid the first person. For example do not say, \u201cWe will begin the backup process by locking the database,\u201d or \u201cI begin the backup process by locking my database instance.\u201d Use the second person. \u201cIf you need to back up your database, start by locking the database first.\u201d In practice, however, it\u2019s more concise to imply second person using the imperative, as in \u201cBefore initiating a backup, lock the database.\u201d When indicated, use the imperative mood. For example: \u201cBack up your databases often\u201d and \u201cTo prevent data loss, back up your databases.\u201d The future perfect is also useful in some cases. For example, \u201cCreating disk snapshots without locking the database will lead to an invalid state.\u201d Avoid helper verbs, as possible, to increase clarity and concision. For example, attempt to avoid \u201cthis does foo\u201d and \u201cthis will do foo\u201d when possible. Use \u201cdoes foo\u201d over \u201cwill do foo\u201d in situations where \u201cthis foos\u201d is unacceptable. Referencing\u00b6 To refer to future or planned functionality in MongoDB or a driver, always link to the Jira case. The Manual\u2019s conf.py provides an :issue: role that links directly to a Jira case (e.g. :issue:\\`SERVER-9001\\`). For non-object references (i.e. functions, operators, methods, database commands, settings) always reference only the first occurrence of the reference in a section. You should always reference objects, except in section headings. Structure references with the why first; the link second. For example, instead of this: Use the Convert a Replica Set to a Sharded Cluster procedure if you have an existing replica set. Type this: To deploy a sharded cluster for an existing replica set, see Convert a Replica Set to a Sharded Cluster. General Formulations\u00b6 Contractions are acceptable insofar as they are necessary to increase readability and flow. Avoid otherwise. Make lists grammatically correct. Do not use a period after every item unless the list item completes the unfinished sentence before the list. Use appropriate commas and conjunctions in the list items. Typically begin a bulleted list with an introductory sentence or clause, with a colon or comma. The following terms are one word: standalone workflow Use \u201cunavailable,\u201d \u201coffline,\u201d or \u201cunreachable\u201d to refer to a mongod instance that cannot be accessed. Do not use the colloquialism \u201cdown.\u201d Always write out units (e.g. \u201cmegabytes\u201d) rather than using abbreviations (e.g. \u201cMB\u201d.) Structural Formulations\u00b6 There should be at least two headings at every nesting level. Within an \u201ch2\u201d block, there should be either: no \u201ch3\u201d blocks, 2 \u201ch3\u201d blocks, or more than 2 \u201ch3\u201d blocks. Section headers are in title case (capitalize first, last, and all important words) and should effectively describe the contents of the section. In a single document you should strive to have section titles that are not redundant and grammatically consistent with each other. Use paragraphs and paragraph breaks to increase clarity and flow. Avoid burying critical information in the middle of long paragraphs. Err on the side of shorter paragraphs. Prefer shorter sentences to longer sentences. Use complex formations only as a last resort, if at all (e.g. compound complex structures that require semi-colons). Avoid paragraphs that consist of single sentences as they often represent a sentence that has unintentionally become too complex or incomplete. However, sometimes such paragraphs are useful for emphasis, summary, or introductions. As a corollary, most sections should have multiple paragraphs. For longer lists and more complex lists, use bulleted items rather than integrating them inline into a sentence. Do not expect that the content of any example (inline or blocked) will be self explanatory. Even when it feels redundant, make sure that the function and use of every example is clearly described. ReStructured Text and Typesetting\u00b6 Place spaces between nested parentheticals and elements in JavaScript examples. For example, prefer { [ a, a, a ] } over {[a,a,a]}. For underlines associated with headers in RST, use: = for heading level 1 or h1s. Use underlines and overlines for document titles. - for heading level 2 or h2s. ~ for heading level 3 or h3s. ` for heading level 4 or h4s. Use hyphens (-) to indicate items of an ordered list. Place footnotes and other references, if you use them, at the end of a section rather than the end of a file. Use the footnote format that includes automatic numbering and a target name for ease of use. For instance a footnote tag may look like: [#note]_ with the corresponding directive holding the body of the footnote that resembles the following: .. [#note]. Do not include .. code-block:: [language] in footnotes. As it makes sense, use the .. code-block:: [language] form to insert literal blocks into the text. While the double colon, ::, is functional, the .. code-block:: [language] form makes the source easier to read and understand. For all mentions of referenced types (i.e. commands, operators, expressions, functions, statuses, etc.) use the reference types to ensure uniform formatting and cross-referencing. Paths and Hostnames\u00b6 Use angle brackets to denote areas that users should input the relevant path, as in --dbpath <path>. When including sample hostnames, use example.com, example.net, or example.org, which are reserved for documentation purposes. See RFC2606 and RFC6761 for more information. Jargon and Common Terms\u00b6 Preferred Term Concept Dispreferred Alternatives Notes document A single, top-level object/record in a MongoDB collection. record, object, row Prefer document over object because of concerns about cross-driver language handling of objects. Reserve record for \u201callocation\u201d of storage. Avoid \u201crow,\u201d as possible. database A group of collections. Refers to a group of data files. This is the \u201clogical\u201d sense of the term \u201cdatabase.\u201d Avoid genericizing \u201cdatabase.\u201d Avoid using database to refer to a server process or a data set. This applies both to the datastoring contexts as well as other (related) operational contexts (command context, authentication/authorization context.) instance A daemon process (e.g. mongos or mongod) process (acceptable sometimes), node (never acceptable), server. Avoid using instance, unless it modifies something specifically. Having a descriptor for a process/instance makes it possible to avoid needing to make mongod or mongos plural. Server and node are both vague and contextually difficult to disambiguate with regards to application servers and underlying hardware. field name The identifier of a value in a document. key, column Avoid introducing unrelated terms for a single field. In the documentation we\u2019ve rarely had to discuss the identifier of a field, so the extra word here isn\u2019t burdensome. field/value The name/value pair that describes a unit of data in MongoDB. key, slot, attribute Use to emphasize the difference between the name of a field and its value For example, \u201c_id\u201d is the field and the default value is an ObjectId. value The data content of a field. data MongoDB A group of processes or a deployment that implements the MongoDB interface. mongo, mongodb, cluster Stylistic preference, mostly. In some cases it\u2019s useful to be able to refer generically to instances (that may be either mongod or mongos.) embedded document An embedded or nested document within a document or an array. nested document map-reduce An operation performed by the mapReduce command. mapReduce, map reduce, map/reduce Avoid confusion with the command, shell helper, and driver interfaces. Makes it possible to discuss the operation generally. cluster A sharded cluster. grid, shard cluster, set, deployment Cluster is a great word for a group of processes; however, it\u2019s important to avoid letting the term become generic. Do not use for any group of MongoDB processes or deployments. sharded cluster A sharded cluster. shard cluster, cluster, sharded system replica set A deployment of replicating mongod programs that provide redundancy and automatic failover. set, replication deployment deployment A group of MongoDB processes, or a standalone mongod instance. cluster, system Typically in the form MongoDB deployment. Includes standalones, replica sets and sharded clusters. data set The collection of physical databases provided by a MongoDB deployment. database, data Important to keep the distinction between the data provided by a mongod or a sharded cluster as distinct from each \u201cdatabase\u201d (i.e. a logical database that refers to a group of collections stored in a single series of data files.) primary The only member of a replica set that can accept writes. master Avoid \u201cprimary member\u201d construction. secondary Read-only members of a replica set that apply operations from the primary\u2019s oplog. slave Accept \u201csecondary member\u201d as needed. primary shard The shard in a cluster that\u2019s \u201cprimary\u201d for a database. primary Avoid ambiguity with primary in the context of replica sets. range based sharding Refers to sharding based on regular shard keys where the range is the value of the field(s) selected as the shard key. hash based sharding Refers to sharding based on hashed shard keys where the range is the hashed value of the field selected as the shard key. Even though hashed sharding is based on ranges of hashes, the sequence of hashes aren\u2019t meaningful to users, and the range-based aspect of hashed shard keys is an implementation detail. sharding Describes the practice of horizontal scaling or partitioning as implemented in sharded clusters. partitioning, horizontal scaling Only use the terms \u201cpartitioning\u201d and \u201chorizontal scaling\u201d to describe what sharding does, and its operation. Don\u2019t refer to sharding as \u201cthe partitioning system.\u201d metadata data about data meta-data, meta data Database Systems and Processes\u00b6 To indicate the entire database system, use \u201cMongoDB,\u201d not mongo or Mongo. To indicate the database process or a server instance, use mongod or mongos. Refer to these as \u201cprocesses\u201d or \u201cinstances.\u201d Reserve \u201cdatabase\u201d for referring to a database structure, i.e., the structure that holds collections and refers to a group of files on disk. Distributed System Terms\u00b6 Refer to partitioned systems as \u201csharded clusters.\u201d Do not use shard clusters or sharded systems. Refer to configurations that run with replication as \u201creplica sets\u201d (or \u201cmaster/slave deployments\u201d) rather than \u201cclusters\u201d or other variants. Data Structure Terms\u00b6 \u201cdocument\u201d refers to \u201crows\u201d or \u201crecords\u201d in a MongoDB database. Potential confusion with \u201cJSON Documents.\u201d Do not refer to documents as \u201cobjects,\u201d because drivers (and MongoDB) do not preserve the order of fields when fetching data. If the order of objects matter, use an array. \u201cfield\u201d refers to a \u201ckey\u201d or \u201cidentifier\u201d of data within a MongoDB document. \u201cvalue\u201d refers to the contents of a \u201cfield\u201d. \u201cembedded document\u201d describes a nested document. Other Terms\u00b6 Use example.net (and .org or .com if needed) for all examples and samples. Hyphenate \u201cmap-reduce\u201d in order to avoid ambiguous reference to the command name. Do not camel-case. Notes on Specific Features\u00b6 Geo-Location While MongoDB is capable of storing coordinates in embedded documents, in practice, users should only store coordinates in arrays. (See: DOCS-41.) \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/meta/translation.html",
      "title": "MongoDB Manual Translation \u2014 MongoDB Manual 3.4",
      "text": "MongoDB Manual Translation\u00b6 The original language of all MongoDB documentation is American English. However it is of critical importance to the documentation project to ensure that speakers of other languages can read and understand the documentation. To this end, the MongoDB Documentation Project is preparing to launch a translation effort to allow the community to help bring the documentation to speakers of other languages. If you would like to express interest in helping to translate the MongoDB documentation once this project is opened to the public, please: complete the MongoDB Contributor Agreement, and join the mongodb-translators user group. The mongodb-translators user group exists to facilitate collaboration between translators and the documentation team at large. You can join the group without signing the Contributor Agreement, but you will not be allowed to contribute translations. See also Contribute to the Documentation Style Guide and Documentation Conventions MongoDB Manual Organization MongoDB Documentation Practices and Processes MongoDB Documentation Build System \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": []
    },
    {
      "slug": "/tutorial/update-documents.html",
      "title": "Update Documents \u2014 MongoDB Manual 3.4",
      "text": "MongoDB CRUD Operations > Update Documents Update Documents\u00b6 Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala This page provides examples of how to update documents in using the following methods in the mongo shell: db.collection.updateOne(<filter>, <update>, <options>) db.collection.updateMany(<filter>, <update>, <options>) db.collection.replaceOne(<filter>, <replacement>, <options>) This page provides examples of how to update documents using the following methods in the PyMongo Python driver: pymongo.collection.Collection.update_one() pymongo.collection.Collection.update_many() pymongo.collection.Collection.replace_one() This page provides examples of how to update documents using the following methods in the Java Synchronous Driver: com.mongodb.client.MongoCollection.updateOne com.mongodb.client.MongoCollection.updateMany com.mongodb.client.MongoCollection.replaceOne This page provides examples of how to update documents using the following methods in the MongoDB Node.js Driver: Collection.updateOne() Collection.updateMany() Collection.replaceOne() This page provides examples of how to update documents using the following methods in the MongoDB PHP Library: MongoDB\\Collection::updateOne() MongoDB\\Collection::updateMany() MongoDB\\Collection::replaceOne() This page provides examples of how to update documents using the following methods in the MongoDB C# Driver: IMongoCollection.UpdateOne() IMongoCollection.UpdateMany() IMongoCollection.ReplaceOne() This page provides examples of how to update documents using the following methods in the MongoDB Perl Driver: MongoDB::Collection::update_one() MongoDB::Collection::update_many() MongoDB::Collection::replace_one() This page provides examples of how to update documents using the following methods in the MongoDB Ruby Driver: Mongo::Collection#update_one() Mongo::Collection#update_many() Mongo::Collection#replace_one() This page provides examples of how to update documents using the following methods in the MongoDB Scala Driver: collection.updateOne() collection.updateMany() collection.replaceOne() The examples on this page use the inventory collection. To create and/or populate the inventory collection, run the following: Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala db.inventory.insertMany( [ { item: \"canvas\", qty: 100, size: { h: 28, w: 35.5, uom: \"cm\" }, status: \"A\" }, { item: \"journal\", qty: 25, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }, { item: \"mat\", qty: 85, size: { h: 27.9, w: 35.5, uom: \"cm\" }, status: \"A\" }, { item: \"mousepad\", qty: 25, size: { h: 19, w: 22.85, uom: \"cm\" }, status: \"P\" }, { item: \"notebook\", qty: 50, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"P\" }, { item: \"paper\", qty: 100, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"D\" }, { item: \"planner\", qty: 75, size: { h: 22.85, w: 30, uom: \"cm\" }, status: \"D\" }, { item: \"postcard\", qty: 45, size: { h: 10, w: 15.25, uom: \"cm\" }, status: \"A\" }, { item: \"sketchbook\", qty: 80, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }, { item: \"sketch pad\", qty: 95, size: { h: 22.85, w: 30.5, uom: \"cm\" }, status: \"A\" } ]); You can run the operation in the web shell below: db.inventory.insert_many([ {\"item\": \"canvas\", \"qty\": 100, \"size\": {\"h\": 28, \"w\": 35.5, \"uom\": \"cm\"}, \"status\": \"A\"}, {\"item\": \"journal\", \"qty\": 25, \"size\": {\"h\": 14, \"w\": 21, \"uom\": \"cm\"}, \"status\": \"A\"}, {\"item\": \"mat\", \"qty\": 85, \"size\": {\"h\": 27.9, \"w\": 35.5, \"uom\": \"cm\"}, \"status\": \"A\"}, {\"item\": \"mousepad\", \"qty\": 25, \"size\": {\"h\": 19, \"w\": 22.85, \"uom\": \"cm\"}, \"status\": \"P\"}, {\"item\": \"notebook\", \"qty\": 50, \"size\": {\"h\": 8.5, \"w\": 11, \"uom\": \"in\"}, \"status\": \"P\"}, {\"item\": \"paper\", \"qty\": 100, \"size\": {\"h\": 8.5, \"w\": 11, \"uom\": \"in\"}, \"status\": \"D\"}, {\"item\": \"planner\", \"qty\": 75, \"size\": {\"h\": 22.85, \"w\": 30, \"uom\": \"cm\"}, \"status\": \"D\"}, {\"item\": \"postcard\", \"qty\": 45, \"size\": {\"h\": 10, \"w\": 15.25, \"uom\": \"cm\"}, \"status\": \"A\"}, {\"item\": \"sketchbook\", \"qty\": 80, \"size\": {\"h\": 14, \"w\": 21, \"uom\": \"cm\"}, \"status\": \"A\"}, {\"item\": \"sketch pad\", \"qty\": 95, \"size\": {\"h\": 22.85, \"w\": 30.5, \"uom\": \"cm\"}, \"status\": \"A\"}]) collection.insertMany(asList( Document.parse(\"{ item: 'canvas', qty: 100, size: { h: 28, w: 35.5, uom: 'cm' }, status: 'A' }\"), Document.parse(\"{ item: 'journal', qty: 25, size: { h: 14, w: 21, uom: 'cm' }, status: 'A' }\"), Document.parse(\"{ item: 'mat', qty: 85, size: { h: 27.9, w: 35.5, uom: 'cm' }, status: 'A' }\"), Document.parse(\"{ item: 'mousepad', qty: 25, size: { h: 19, w: 22.85, uom: 'cm' }, status: 'P' }\"), Document.parse(\"{ item: 'notebook', qty: 50, size: { h: 8.5, w: 11, uom: 'in' }, status: 'P' }\"), Document.parse(\"{ item: 'paper', qty: 100, size: { h: 8.5, w: 11, uom: 'in' }, status: 'D' }\"), Document.parse(\"{ item: 'planner', qty: 75, size: { h: 22.85, w: 30, uom: 'cm' }, status: 'D' }\"), Document.parse(\"{ item: 'postcard', qty: 45, size: { h: 10, w: 15.25, uom: 'cm' }, status: 'A' }\"), Document.parse(\"{ item: 'sketchbook', qty: 80, size: { h: 14, w: 21, uom: 'cm' }, status: 'A' }\"), Document.parse(\"{ item: 'sketch pad', qty: 95, size: { h: 22.85, w: 30.5, uom: 'cm' }, status: 'A' }\") )); db.collection('inventory').insertMany([ { item: \"canvas\", qty: 100, size: {h: 28, w: 35.5, uom: \"cm\"}, status: \"A\"}, { item: \"journal\", qty: 25, size: {h: 14, w: 21, uom: \"cm\"}, status: \"A\"}, { item: \"mat\", qty: 85, size: {h: 27.9, w: 35.5, uom: \"cm\"}, status: \"A\"}, { item: \"mousepad\", qty: 25, size: {h: 19, w: 22.85, uom: \"cm\"}, status: \"P\"}, { item: \"notebook\", qty: 50, size: {h: 8.5, w: 11, uom: \"in\"}, status: \"P\"}, { item: \"paper\", qty: 100, size: {h: 8.5, w: 11, uom: \"in\"}, status: \"D\"}, { item: \"planner\", qty: 75, size: {h: 22.85, w: 30, uom: \"cm\"}, status: \"D\"}, { item: \"postcard\", qty: 45, size: {h: 10, w: 15.25, uom: \"cm\"}, status: \"A\"}, { item: \"sketchbook\", qty: 80, size: {h: 14, w: 21, uom: \"cm\"}, status: \"A\"}, { item: \"sketch pad\", qty: 95, size: {h: 22.85, w: 30.5, uom: \"cm\"}, status: \"A\"} ]) .then(function(result) { // process result }) $insertManyResult = $db->inventory->insertMany([ [ 'item' => 'canvas', 'qty' => 100, 'size' => ['h' => 28, 'w' => 35.5, 'uom' => 'cm'], 'status' => 'A', ], [ 'item' => 'journal', 'qty' => 25, 'size' => ['h' => 14, 'w' => 21, 'uom' => 'cm'], 'status' => 'A', ], [ 'item' => 'mat', 'qty' => 85, 'size' => ['h' => 27.9, 'w' => 35.5, 'uom' => 'cm'], 'status' => 'A', ], [ 'item' => 'mousepad', 'qty' => 25, 'size' => ['h' => 19, 'w' => 22.85, 'uom' => 'cm'], 'status' => 'P', ], [ 'item' => 'notebook', 'qty' => 50, 'size' => ['h' => 8.5, 'w' => 11, 'uom' => 'in'], 'status' => 'P', ], [ 'item' => 'paper', 'qty' => 100, 'size' => ['h' => 8.5, 'w' => 11, 'uom' => 'in'], 'status' => 'D', ], [ 'item' => 'planner', 'qty' => 75, 'size' => ['h' => 22.85, 'w' => 30, 'uom' => 'cm'], 'status' => 'D', ], [ 'item' => 'postcard', 'qty' => 45, 'size' => ['h' => 10, 'w' => 15.25, 'uom' => 'cm'], 'status' => 'A', ], [ 'item' => 'sketchbook', 'qty' => 80, 'size' => ['h' => 14, 'w' => 21, 'uom' => 'cm'], 'status' => 'A', ], [ 'item' => 'sketch pad', 'qty' => 95, 'size' => ['h' => 22.85, 'w' => 30.5, 'uom' => 'cm'], 'status' => 'A', ], ]); var documents = new[] { new BsonDocument { { \"item\", \"canvas\" }, { \"qty\", 100 }, { \"size\", new BsonDocument { { \"h\", 28 }, { \"w\", 35.5 }, { \"uom\", \"cm\" } } }, { \"status\", \"A\" } }, new BsonDocument { { \"item\", \"journal\" }, { \"qty\", 25 }, { \"size\", new BsonDocument { { \"h\", 14 }, { \"w\", 21 }, { \"uom\", \"cm\" } } }, { \"status\", \"A\" } }, new BsonDocument { { \"item\", \"mat\" }, { \"qty\", 85 }, { \"size\", new BsonDocument { { \"h\", 27.9 }, { \"w\", 35.5 }, { \"uom\", \"cm\" } } }, { \"status\", \"A\" } }, new BsonDocument { { \"item\", \"mousepad\" }, { \"qty\", 25 }, { \"size\", new BsonDocument { { \"h\", 19 }, { \"w\", 22.85 }, { \"uom\", \"cm\" } } }, { \"status\", \"P\" } }, new BsonDocument { { \"item\", \"notebook\" }, { \"qty\", 50 }, { \"size\", new BsonDocument { { \"h\", 8.5 }, { \"w\", 11 }, { \"uom\", \"in\" } } }, { \"status\", \"P\" } }, new BsonDocument { { \"item\", \"paper\" }, { \"qty\", 100 }, { \"size\", new BsonDocument { { \"h\", 8.5 }, { \"w\", 11 }, { \"uom\", \"in\" } } }, { \"status\", \"D\" } }, new BsonDocument { { \"item\", \"planner\" }, { \"qty\", 75 }, { \"size\", new BsonDocument { { \"h\", 22.85 }, { \"w\", 30 }, { \"uom\", \"cm\" } } }, { \"status\", \"D\" } }, new BsonDocument { { \"item\", \"postcard\" }, { \"qty\", 45 }, { \"size\", new BsonDocument { { \"h\", 10 }, { \"w\", 15.25 }, { \"uom\", \"cm\" } } }, { \"status\", \"A\" } }, new BsonDocument { { \"item\", \"sketchbook\" }, { \"qty\", 80 }, { \"size\", new BsonDocument { { \"h\", 14 }, { \"w\", 21 }, { \"uom\", \"cm\" } } }, { \"status\", \"A\" } }, new BsonDocument { { \"item\", \"sketch pad\" }, { \"qty\", 95 }, { \"size\", new BsonDocument { { \"h\", 22.85 }, { \"w\", 30.5 }, { \"uom\", \"cm\" } } }, { \"status\", \"A\" } }, }; collection.InsertMany(documents); $db->coll(\"inventory\")->insert_many( [ { item => \"canvas\", qty => 100, size => { h => 28, w => 35.5, uom => \"cm\" }, status => \"A\" }, { item => \"journal\", qty => 25, size => { h => 14, w => 21, uom => \"cm\" }, status => \"A\" }, { item => \"mat\", qty => 85, size => { h => 27.9, w => 35.5, uom => \"cm\" }, status => \"A\" }, { item => \"mousepad\", qty => 25, size => { h => 19, w => 22.85, uom => \"cm\" }, status => \"P\" }, { item => \"notebook\", qty => 50, size => { h => 8.5, w => 11, uom => \"in\" }, status => \"P\" }, { item => \"paper\", qty => 100, size => { h => 8.5, w => 11, uom => \"in\" }, status => \"D\" }, { item => \"planner\", qty => 75, size => { h => 22.85, w => 30, uom => \"cm\" }, status => \"D\" }, { item => \"postcard\", qty => 45, size => { h => 10, w => 15.25, uom => \"cm\" }, status => \"A\" }, { item => \"sketchbook\", qty => 80, size => { h => 14, w => 21, uom => \"cm\" }, status => \"A\" }, { item => \"sketch pad\", qty => 95, size => { h => 22.85, w => 30.5, uom => \"cm\" }, status => \"A\" } ] ); client[:inventory].insert_many([ { item: 'canvas', qty: 100, size: { h: 28, w: 35.5, uom: 'cm' }, status: 'A' }, { item: 'journal', qty: 25, size: { h: 14, w: 21, uom: 'cm' }, status: 'A' }, { item: 'mat', qty: 85, size: { h: 27.9, w: 35.5, uom: 'cm' }, status: 'A' }, { item: 'mousepad', qty: 25, size: { h: 19, w: 22.85, uom: 'cm' }, status: 'P' }, { item: 'notebook', qty: 50, size: { h: 8.5, w: 11, uom: 'in' }, status: 'P' }, { item: 'paper', qty: 100, size: { h: 8.5, w: 11, uom: 'in' }, status: 'D' }, { item: 'planner', qty: 75, size: { h: 22.85, w: 30, uom: 'cm' }, status: 'D' }, { item: 'postcard', qty: 45, size: { h: 10, w: 15.25, uom: 'cm' }, status: 'A' }, { item: 'sketchbook', qty: 80, size: { h: 14, w: 21, uom: 'cm' }, status: 'A' }, { item: 'sketch pad', qty: 95, size: { h: 22.85, w: 30.5, uom: 'cm' }, status: 'A' } ]) collection.insertMany(Seq( Document(\"\"\"{ item: \"canvas\", qty: 100, size: { h: 28, w: 35.5, uom: \"cm\" }, status: \"A\" }\"\"\"), Document(\"\"\"{ item: \"journal\", qty: 25, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }\"\"\"), Document(\"\"\"{ item: \"mat\", qty: 85, size: { h: 27.9, w: 35.5, uom: \"cm\" }, status: \"A\" }\"\"\"), Document(\"\"\"{ item: \"mousepad\", qty: 25, size: { h: 19, w: 22.85, uom: \"cm\" }, status: \"P\" }\"\"\"), Document(\"\"\"{ item: \"notebook\", qty: 50, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"P\" }\"\"\"), Document(\"\"\"{ item: \"paper\", qty: 100, size: { h: 8.5, w: 11, uom: \"in\" }, status: \"D\" }\"\"\"), Document(\"\"\"{ item: \"planner\", qty: 75, size: { h: 22.85, w: 30, uom: \"cm\" }, status: \"D\" }\"\"\"), Document(\"\"\"{ item: \"postcard\", qty: 45, size: { h: 10, w: 15.25, uom: \"cm\" }, status: \"A\" }\"\"\"), Document(\"\"\"{ item: \"sketchbook\", qty: 80, size: { h: 14, w: 21, uom: \"cm\" }, status: \"A\" }\"\"\"), Document(\"\"\"{ item: \"sketch pad\", qty: 95, size: { h: 22.85, w: 30.5, uom: \"cm\" }, status: \"A\" }\"\"\") )).execute() Update Documents in a Collection\u00b6 To update a document, MongoDB provides update operators, such as $set, to modify field values. Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala To use the update operators, pass to the update methods an update document of the form: { <update operator>: { <field1>: <value1>, ... }, <update operator>: { <field2>: <value2>, ... }, ... } To use the update operators, pass to the update methods an update document of the form: { <update operator>: { <field1>: <value1>, ... }, <update operator>: { <field2>: <value2>, ... }, ... } The driver provides the com.mongodb.client.model.Updates class to facilitate the creation of update documents. For example: combine(set( <field1>, <value1>), set(<field2>, <value2> ) ) For a list of the update helpers, see com.mongodb.client.model.Updates. { <update operator>: { <field1>: <value1>, ... }, <update operator>: { <field2>: <value2>, ... }, ... } To use the update operators, pass to the update methods an update document of the form: [ <update operator> => [ <field1> => <value1>, ... ], <update operator> => [ <field2> => <value2>, ... ], ... ] { <update operator> => { <field1> => <value1>, ... }, <update operator> => { <field2> => <value2>, ... }, ... } To use the update operators, pass to the update methods an update document of the form: { <update operator> => { <field1> => <value1>, ... }, <update operator> => { <field2> => <value2>, ... }, ... } { <update operator> => { <field1> => <value1>, ... }, <update operator> => { <field2> => <value2>, ... }, ... } To use the update operators, pass to the update methods an update document of the form: ( set (<field1>, <value1>), set (<field2>, <value2>), ... ) Some update operators, such as $set, will create the field if the field does not exist. See the individual update operator reference for details. Update a Single Document\u00b6 Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala The following example uses the db.collection.updateOne() method on the inventory collection to update the first document where item equals \"paper\": The following example uses the update_one() method on the inventory collection to update the first document where item equals \"paper\": The following example uses the com.mongodb.client.MongoCollection.updateOne method on the inventory collection to update the first document where item equals \"paper\": The following example uses the Collection.updateOne() method on the inventory collection to update the first document where item equals \"paper\": The following example uses the updateOne() method on the inventory collection to update the first document where item equals \"paper\": The following example uses the IMongoCollection.UpdateOne() method on the inventory collection to update the first document where item equals \"paper\": The following example uses the update_one() method on the inventory collection to update the first document where item equals \"paper\": The following example uses the update_one() method on the inventory collection to update the first document where item equals \"paper\": The following example uses the updateOne() method on the inventory collection to update the first document where item equals \"paper\": Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala db.inventory.updateOne( { item: \"paper\" }, { $set: { \"size.uom\": \"cm\", status: \"P\" }, $currentDate: { lastModified: true } } ) db.inventory.update_one( {\"item\": \"paper\"}, {\"$set\": {\"size.uom\": \"cm\", \"status\": \"P\"}, \"$currentDate\": {\"lastModified\": True}}) collection.updateOne(eq(\"item\", \"paper\"), combine(set(\"size.uom\", \"cm\"), set(\"status\", \"P\"), currentDate(\"lastModified\"))); db.collection('inventory').updateOne( { item: \"paper\" }, { $set: { \"size.uom\": \"cm\", status: \"P\" }, $currentDate: { lastModified: true } }) .then(function(result) { // process result }) $updateResult = $db->inventory->updateOne( ['item' => 'paper'], [ '$set' => ['size.uom' => 'cm', 'status' => 'P'], '$currentDate' => ['lastModified' => true], ] ); var filter = Builders<BsonDocument>.Filter.Eq(\"item\", \"paper\"); var update = Builders<BsonDocument>.Update.Set(\"size.uom\", \"cm\").Set(\"status\", \"P\").CurrentDate(\"lastModified\"); var result = collection.UpdateOne(filter, update); # For boolean values, use boolean.pm for 'true' and 'false' $db->coll(\"inventory\")->update_one( { item => \"paper\" }, { '$set' => { \"size.uom\" => \"cm\", status => \"P\" }, '$currentDate' => { lastModified => true } } ); client[:inventory].update_one({ item: 'paper'}, { '$set' => { 'size.uom' => 'cm', 'status' => 'P' }, '$currentDate' => { 'lastModified' => true } }) collection.updateOne(equal(\"item\", \"paper\"), combine(set(\"size.uom\", \"cm\"), set(\"status\", \"P\"), currentDate(\"lastModified\")) ).execute() The update operation: uses the $set operator to update the value of the size.uom field to \"cm\" and the value of the status field to \"P\", uses the $currentDate operator to update the value of the lastModified field to the current date. If lastModified field does not exist, $currentDate will create the field. See $currentDate for details. Update Multiple Documents\u00b6 New in version 3.2. Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala The following example uses the db.collection.updateMany() method on the inventory collection to update all documents where qty is less than 50: The following example uses the update_many() method on the inventory collection to update all documents where qty is less than 50: The following example uses the com.mongodb.client.MongoCollection.updateMany method on the inventory collection to update all documents where qty is less than 50: The following example uses the Collection.updateMany() method on the inventory collection to update all documents where qty is less than 50: The following example uses the updateMany() method on the inventory collection to update all documents where qty is less than 50: The following example uses the IMongoCollection.UpdateMany() method on the inventory collection to update all documents where qty is less than 50: The following example uses the update_many() method on the inventory collection to update all documents where qty is less than 50: The following example uses the update_many() method on the inventory collection to update all documents where qty is less than 50: The following example uses the updateMany() method on the inventory collection to update all documents where qty is less than 50: Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala db.inventory.updateMany( { \"qty\": { $lt: 50 } }, { $set: { \"size.uom\": \"in\", status: \"P\" }, $currentDate: { lastModified: true } } ) db.inventory.update_many( {\"qty\": {\"$lt\": 50}}, {\"$set\": {\"size.uom\": \"in\", \"status\": \"P\"}, \"$currentDate\": {\"lastModified\": True}}) collection.updateMany(lt(\"qty\", 50), combine(set(\"size.uom\", \"in\"), set(\"status\", \"P\"), currentDate(\"lastModified\"))); db.collection('inventory').updateMany( { qty: { $lt: 50 } }, { $set: { \"size.uom\": \"in\", status: \"P\" }, $currentDate: { lastModified: true } }) .then(function(result) { // process result }) $updateResult = $db->inventory->updateMany( ['qty' => ['$lt' => 50]], [ '$set' => ['size.uom' => 'cm', 'status' => 'P'], '$currentDate' => ['lastModified' => true], ] ); var filter = Builders<BsonDocument>.Filter.Lt(\"qty\", 50); var update = Builders<BsonDocument>.Update.Set(\"size.uom\", \"in\").Set(\"status\", \"P\").CurrentDate(\"lastModified\"); var result = collection.UpdateMany(filter, update); # For boolean values, use boolean.pm for 'true' and 'false' $db->coll(\"inventory\")->update_many( { qty => { '$lt' => 50 } }, { '$set' => { \"size.uom\" => \"in\", status => \"P\" }, '$currentDate' => { lastModified => true } } ); client[:inventory].update_many({ qty: { '$lt' => 50 } }, { '$set' => { 'size.uom' => 'in', 'status' => 'P' }, '$currentDate' => { 'lastModified' => true } }) collection.updateMany(lt(\"qty\", 50), combine(set(\"size.uom\", \"in\"), set(\"status\", \"P\"), currentDate(\"lastModified\")) ).execute() The update operation: uses the $set operator to update the value of the size.uom field to \"in\" and the value of the status field to \"P\", uses the $currentDate operator to update the value of the lastModified field to the current date. If lastModified field does not exist, $currentDate will create the field. See $currentDate for details. Replace a Document\u00b6 Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to db.collection.replaceOne(). To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to replace_one(). To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to com.mongodb.client.MongoCollection.replaceOne. To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to Collection.replaceOne(). To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to replaceOne(). To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to IMongoCollection.ReplaceOne(). To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to replace_one(). To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to replace_one(). To replace the entire content of a document except for the _id field, pass an entirely new document as the second argument to replaceOne() When replacing a document, the replacement document must consist of only field/value pairs; i.e. do not include update operators expressions. The replacement document can have different fields from the original document. In the replacement document, you can omit the _id field since the _id field is immutable; however, if you do include the _id field, it must have the same value as the current value. The following example replaces the first document from the inventory collection that matches the filter item equals \"paper\": Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala db.inventory.replaceOne( { item: \"paper\" }, { item: \"paper\", instock: [ { warehouse: \"A\", qty: 60 }, { warehouse: \"B\", qty: 40 } ] } ) db.inventory.replace_one( {\"item\": \"paper\"}, {\"item\": \"paper\", \"instock\": [ {\"warehouse\": \"A\", \"qty\": 60}, {\"warehouse\": \"B\", \"qty\": 40}]}) collection.replaceOne(eq(\"item\", \"paper\"), Document.parse(\"{ item: 'paper', instock: [ { warehouse: 'A', qty: 60 }, { warehouse: 'B', qty: 40 } ] }\")); db.collection('inventory').updateOne( { item: \"paper\" }, { item: \"paper\", instock: [ { warehouse: \"A\", qty: 60 }, { warehouse: \"B\", qty: 40 } ]}) .then(function(result) { // process result }) $updateResult = $db->inventory->replaceOne( ['item' => 'paper'], [ 'item' => 'paper', 'instock' => [ ['warehouse' => 'A', 'qty' => 60], ['warehouse' => 'B', 'qty' => 40], ], ] ); var filter = Builders<BsonDocument>.Filter.Eq(\"item\", \"paper\"); var replacement = new BsonDocument { { \"item\", \"paper\" }, { \"instock\", new BsonArray { new BsonDocument { { \"warehouse\", \"A\" }, { \"qty\", 60 } }, new BsonDocument { { \"warehouse\", \"B\" }, { \"qty\", 40 } } } } }; var result = collection.ReplaceOne(filter, replacement); $db->coll(\"inventory\")->replace_one( { item => \"paper\" }, { item => \"paper\", instock => [ { warehouse => \"A\", qty => 60 }, { warehouse => \"B\", qty => 40 } ] } ); client[:inventory].replace_one({ item: 'paper' }, { item: 'paper', instock: [ { warehouse: 'A', qty: 60 }, { warehouse: 'B', qty: 40 } ] }) collection.replaceOne(equal(\"item\", \"paper\"), Document(\"\"\"{ item: \"paper\", instock: [ { warehouse: \"A\", qty: 60 }, { warehouse: \"B\", qty: 40 } ] }\"\"\") ).execute() Behavior\u00b6 Atomicity\u00b6 All write operations in MongoDB are atomic on the level of a single document. For more information on MongoDB and atomicity, see Atomicity and Transactions. _id Field\u00b6 Once set, you cannot update the value of the _id field nor can you replace an existing document with a replacement document that has a different _id field value. Document Size\u00b6 When performing update operations that increase the document size beyond the allocated space for that document, the update operation relocates the document on disk. Field Order\u00b6 MongoDB preserves the order of the document fields following write operations except for the following cases: The _id field is always the first field in the document. Updates that include renaming of field names may result in the reordering of fields in the document. Changed in version 2.6: Starting in version 2.6, MongoDB actively attempts to preserve the field order in a document. Before version 2.6, MongoDB did not actively preserve the order of the fields in a document. Upsert Option\u00b6 Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala If updateOne(), updateMany(), or replaceOne() includes upsert : true and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. If update_one(), update_many(), or replace_one() includes upsert : true and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. If the update and replace methods include com.mongodb.client.model.UpdateOptions document that specifies com.mongodb.client.model.UpdateOptions.upsert(true) and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. If updateOne(), updateMany(), or replaceOne() include upsert : true in the options parameter document and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. If updateOne(), updateMany(), or replaceOne() includes upsert => true and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. If UpdateOne(), UpdateMany(), or ReplaceOne() includes an UpdateOptions argument instance with the IsUpsert option set to true and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. If update_one(), update_many(), or replace_one() includes upsert => true and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. If update_one(), update_many(), or replace_one() includes upsert => true and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. If updateOne(), updateMany(), or replaceOne() includes upsert => true and no documents match the specified filter, then the operation creates a new document and inserts it. If there are matching documents, then the operation modifies or replaces the matching document or documents. For details on the new document created, see the individual reference pages for the methods. Write Acknowledgement\u00b6 With write concerns, you can specify the level of acknowledgement requested from MongoDB for write operations. For details, see Write Concern. Mongo Shell Python Java (Sync) Node.js PHP Other C# Perl Ruby Scala [1]You can use the DBQuery.shellBatchSize to change the number of iteration from the default value 20. See Working with the mongo Shell for more information. See also db.collection.updateOne() db.collection.updateMany() db.collection.replaceOne() Additional Methods See also pymongo.collection.Collection.update_one() pymongo.collection.Collection.update_many() pymongo.collection.Collection.replace_one() Additional Methods See also com.mongodb.client.MongoCollection.updateOne com.mongodb.client.MongoCollection.updateMany com.mongodb.client.MongoCollection.replaceOne Additional Java Synchronous Driver Write Examples See also Collection.updateOne() Collection.updateMany() Collection.replaceOne() Additional Methods See also MongoDB\\Collection::updateOne() MongoDB\\Collection::updateMany() MongoDB\\Collection::replaceOne() Additional Methods See also IMongoCollection.UpdateOne() IMongoCollection.UpdateMany() IMongoCollection.ReplaceOne() Additional Methods See also MongoDB::Collection::update_one() MongoDB::Collection::update_many() MongoDB::Collection::replace_one() Additional Methods See also Mongo::Collection#update_one() Mongo::Collection#update_many() Mongo::Collection#replace_one() See also collection.updateOne() collection.updateMany() collection.replaceOne() Additional Methods Update Methods \u2190 Iterate a Cursor in the mongo Shell Update Methods \u2192 \u00a9 MongoDB, Inc 2008-2017. MongoDB, Mongo, and the leaf logo are registered trademarks of MongoDB, Inc.",
      "preview": "",
      "tags": [
        "update documents",
        "update all documents",
        "update single document",
        "modify documents",
        "update fields in documents",
        "update collection",
        "MongoDB Manual"
      ]
    }
  ]
}